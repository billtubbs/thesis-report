% !TEX encoding = UTF-8 Unicode
\chapter{Simulation results}  \label{chap-simulation}
%
This chapter describes numerical simulations carried out to demonstrate and evaluate the disturbance models and observer designs described in Chapter \ref{chap-methods}. Section \ref{section:sim-RODDs} presents a few simulated examples of different \gls{RODD}s. Section \ref{section:sim-obs-lin} describes experiments to evaluate the multiple-model observers in estimating the states of two simulated systems, a single-input single-output (SISO) linear system with one \gls{RODD} step disturbance, and a 2-input, 2-output linear system with two \gls{RODD} step disturbances. Section \ref{section:sim-ore-SISO} describes an experiment to evaluate the observer performance on the simulated grinding circuit model with one output variable and a step disturbance in the ore feed mix. \textcolor{red}{Section \ref{section:sim-ore-mimo-ctrl} describes an experiment to evaluate the observers in a multi-variable feedback control scenario with the simulated grinding circuit model.}


\section{Generating RODD disturbances} \label{section:sim-RODDs}

\gls{RODD}s are easy to generate by numerical simulation.  Plot (a) in Figure \ref{fig:rodd-sim-plots} shows a random shock sequence (\ref{eq:wpk1}) of length 1000 samples generated using a pseudo-random number generator. Plots (b), (c), and (d) show step, ramp and exponential change disturbances generated with this random shock sequence using the \gls{RODD} models in (\ref{eq:RODD-step}), (\ref{eq:RODD-ramp}), and (\ref{eq:RODD-exp}). Figure \ref{fig:rodd-sim-plot2} shows a combined RODD with abruptly changing ramps and steps (\ref{eq:RODD-step-ramp}).
\begin{figure}[htp]
	\centering
	\includegraphics[width=13cm]{images/rodd_sim_plots.pdf}
	\caption{Examples of \gls{RODD}s}
	\label{fig:rodd-sim-plots}
\end{figure}
\begin{figure}[htp]
	\centering
	\includegraphics[width=13cm]{images/rodd_sim_plot2.pdf}
	\caption{A \gls{RODD} with steps and ramps}
	\label{fig:rodd-sim-plot2}
\end{figure}


\section{Observer evaluation with linear systems} \label{section:sim-obs-lin}

\subsection{SISO linear system} \label{sim-obs-lin-1}

To demonstrate state estimation in the presence of \gls{RODD}s, a single \gls{RODD} was simulated at the input to a SISO process represented by a discrete-time linear model, as shown in the functional diagram in Figure \ref{fig:sim-sys-diag-siso}. In addition to the unmeasured \gls{RODD}, $p(k)$, the process has a known input, $u(k)$, and a measured output, $y_M(k)$. The measurements are simulated by adding a random noise, $v(k)$, with zero mean and standard deviation, \gls{sigmaM}, to the output of the process. At each sample time, the input and measured output are passed to an observer, which calculates estimates of the process states, $\hat{\mathbf{x}}(k|k)$, and an estimate of the process output, $\hat{y}(k|k)$.
\begin{figure}[htp]
	\centering
	\includegraphics[width=11.5cm]{images/sim-sys-diag-siso.pdf}
	\caption{Functional diagram of the simulated SISO system with observer}
	\label{fig:sim-sys-diag-siso}
\end{figure}

For the purposes of this experiment, the linear model used to represent the process was the stable first order system,
\begin{equation}
	\frac{B(z^{-1})}{A(z^{-1})} = \frac{0.3z^{-1}}{1-0.7z^{-1}}
\end{equation}
with a sampling period, \gls{Ts}, of 0.5.

The \gls{RODD} was a step disturbance created by setting
\begin{equation}
	\frac{C(z^{-1})}{D(z^{-1})} = \frac{1}{1-z^{-1}}.
\end{equation}
The random shock, $w_p(k)$, was defined by (\ref{eq:wpik2}) with $\epsilon=0.01$, $\sigma_{w_p}=0.01$, and $b=100$.

The state-space model used to simulate the augmented system was
\begin{equation} \label{eq:sim-sys-siso-ss-aug}
	\begin{split}
	\mathbf{x}_{a}(k+1) & =\left[\begin{array}{cc}
		0.7 & 1 \\
		0 & 1
	\end{array}\right] \mathbf{x}_{a}(k)+\left[\begin{array}{l}
		1 \\
		0
	\end{array}\right] u(k) + \mathbf{w}_{a}(k) \\
	y(k) & =\left[\begin{array}{cc}
	0.3 & 0
\end{array}\right] \mathbf{x}_{a}(k) + v(k)
\end{split}
\end{equation}
where
\begin{equation} \label{eq:sim-sys-siso-ss-aug2}
		\mathbf{x}_{a}(k) = \left[\begin{array}{l}
			x_{a,1}(k) \\
			x_{a,2}(k)
		\end{array}\right] = \left[\begin{array}{l}
		x_{1}(k) \\
		p(k)
	\end{array}\right], \mathbf{w}_{a}(k) = \left[\begin{array}{l}
	w_1(k) \\
	w_{p}(k)
\end{array}\right] .
\end{equation}

Note that with this representation, the second model state $x_{a,2}(k)$ corresponds exactly to the input disturbance $p(k)$.

\subsection{Analysis of sub-optimal estimators} \label{sim-obs-lin-1-SKF-analysis}

\begin{figure}[htp]
	\centering
	\includegraphics[width=13cm]{images/rod_MKF_SF_test_sim_MKF_SF95_ioplot.pdf}
	\caption{Simulation of a SISO linear system with a \gls{RODD} input disturbance}
	\label{fig:rod-obs-sim-test-ioplot-SF95}
\end{figure}
To understand and investigate the behaviour of the observers, the system (\ref{eq:sim-sys-siso-ss-aug}) was first simulated for 100 sample periods with two pre-determined shocks, no persistent disturbance ($\sigma_{w_p}=0$), and no measurement noise ($\sigma_M=0$). Figure \ref{fig:rod-obs-sim-test-ioplot-SF95} shows the simulation data. The two lower plots show the system inputs, including the random shock signal. The upper two plots show the system states and outputs as well as the estimates of a sub-optimal multiple-model observer using the sequence fusion algorithm described by \cite{robertson_detection_1995} with parameters $N_f=15$, $n_\text{max}=1$, and $N_d=5$.

\begin{figure}[htp]
	\centering
	\includegraphics[width=12cm]{images/rod_MKF_test_sim_MKF_SF95_prob.png}
	\caption{Multi-model observer probability estimates – MKF--SF95}
	\label{fig:rod-obs-sim-test-probs-SF95}
\end{figure}
The two plots in Figure \ref{fig:rod-obs-sim-test-probs-SF95} provide insight into the computations of the observer, which is labelled `MKF--SF95'. The upper plot shows four time series of the trace (i.e. the sum of the elements on the main diagonal) of the merged error covariance matrices, $\mathbf{P}_m(k)$ for $m=1,2,...,n_m$. The diagonal values of $\mathbf{P}_m(k)$ may be interpreted as indicators of the magnitude of the errors of the state estimates. Recall that $\mathbf{P}_m(k)$ is time-varying and influenced by the process noise covariance, $\mathcal{Q}(\gamma_f(k))$, which switches according to the hypothesis sequences (\ref{eq:Pfkp1}). In this simulation, the covariances at time $t=0$ were initialized to the identify matrix ($\mathbf{P}_m(0)=\mathbf{I}_2$). It can be seen that the trace values initially drop rapidly and tend towards zero, however, at certain times, they increase sharply to a peak before dropping again. The sharp peaks are caused by the shock hypotheses ($\gamma_m(k)=1$) of the sequences.

The lower plot shows the conditional likelihood estimates of the four hypotheses given the data up to time $k$ after the merging step(\ref{eq:xmkymk_hat_MKF}). The conditional likelihoods were initialized with equal values ($\operatorname{Pr}\left(\Gamma_m(0) \mid \mathbf{Y}(0)\right)=1/n_m$). It can be seen that the likelihoods of each hypothesis settle on a steady-state by $t=5$ and hypothesis 1 dominates the probability distribution until $t=10$. This means that the merged estimates of the observer are determined almost completely by hypothesis 1 during this period. This makes sense since hypothesis 1 represents a sequence containing no shocks and the first shock does not occur until $t=9.5$. A short time after the first shock, the probability density shifts to hypothesis sequence 3 which happens to assume a shock at $t=10$. This is evident in the upper plot where it can be seen that the error covariance of hypothesis 3 increases and peaks at $t=10.5$. The probability switches from hypothesis 1 to 3 by $t=11.5$ and remains there until $t=17$ when it shifts back to hypothesis 1. This final shift can be explained by the fusion horizon, \gls{nf}, which in this case is 15 sample periods or 7.5 time units. Hypothesis 3 assumes another shock occurs at this time, which is not the case. Therefore, hypothesis 1 becomes the most likely hypothesis after that. The second shock occurs at $t=29$, which is not as favourable since it does not align well with the shocks in any of the hypothesis sequences. Initially, the likelihood switches to hypotheses 4, which assumes a shock at $t=27.5$ but then it switches to hypothesis 2, which assumes a shock at $t=30$. Again, the probability remains high until the next shock is scheduled, at which point hypothesis 1 becomes the most likely again.

\begin{figure}[htp]
	\centering
	\includegraphics[width=13cm]{images/rod_MKF_test_sim_MKF_SF95_x_est.pdf}
	\caption{Multi-model observer state estimates – MKF--SF95}
	\label{fig:rod-obs-sim-test-x_est-SF95}
\end{figure}
Figure \ref{fig:rod-obs-sim-test-x_est-SF95} shows the merged state estimates associated with each hypothesis (thin coloured lines), as well as the overall state estimate (thick blue lines) and the true states of the system (dashed lines). These plots reveal the role that each hypothesis plays in the overall estimates. The estimates of hypothesis 3 (purple lines) are the first to respond to the first shock at time $t=9.5$ and the overall estimate closely follows this hypothesis. The other estimates (green, yellow and orange lines) respond at later intervals and do not play a role in the overall estimate. After the second shock occurs, the overall estimate follows that of hypothesis 2, however, this estimate lags behind the true system state and the response of the output estimate is slower and overshoots the true system output for a few time steps. These simulation results demonstrate that the performance of the sequence fusion algorithm is somewhat sensitive to the timing of the true shocks.

As described in Section \ref{subsec-fusion}, Robertson and coworkers proposed an alternative implementation of the sequence fusion algorithm \citep{robertson_method_1998}. There are two differences between this and the previous algorithm. Firstly, shocks are assumed to act over the duration of the detection interval rather than at one sample time within it. Secondly, the variance of the shocks, $b^2w_{p}^2(k)$, is reduced according to the interval length, (\ref{eq:wpdk}).
%% TODO: add parameters to above? with $f=15$ $m=1$ and $d=5$.

\begin{figure}[htp]
	\centering
	\includegraphics[width=12cm]{images/rod_MKF_test_sim_MKF_SF98_prob.png}
	\caption{Multi-model observer probability estimates – MKF--SF98}
	\label{fig:rod-obs-sim-test-probs-SF98}
\end{figure}
Figures \ref{fig:rod-obs-sim-test-probs-SF98} and \ref{fig:rod-obs-sim-test-x_est-SF98} show the results of simulating the 1998 version of the observer, labelled `MKF--SF98', with the same simulation data. The effect of the modifications on the error covariance is clear. The traces of the error covariance peak at a lower value and the peaks are sustained for the duration of the detection intervals, unlike in the 1995 version. The switching of the hypothesis probabilities is also different. After the first shock at $t=9.5$ there is a slightly longer delay before the probability of hypothesis 3 begins to respond. However, in this case the probability then shifts to hypothesis 2. This may be due to the fact that the shock occurred in the middle of the detection interval of hypothesis 2. After the second shock at $t=29$ the response is again slower and hypothesis 4 becomes the most probable.

Figure \ref{fig:rod-obs-sim-test-x_est-SF98} shows the merged state estimates of each hypothesis, the overall estimates, and the true system states for the 1998 version of the algorithm. The behaviour of this algorithm is quite complex. The estimates take slightly longer to begin responding to shocks but there is noticeably less overshoot of the estimates in this simulation compared to the 1995 version.   
\begin{figure}[htp]
	\centering
	\includegraphics[width=13cm]{images/rod_MKF_test_sim_MKF_SF98_x_est.pdf}
	\caption{Multi-model observer state estimates – MKF--SF98}
	\label{fig:rod-obs-sim-test-x_est-SF98}
\end{figure}

\begin{figure}[htp]
	\centering
	\includegraphics[width=12cm]{images/rod_MKF_test_sim_MKF_SP_prob.png}
	\caption{Multi-model observer probability estimates – MKF--SP}
	\label{fig:rod-obs-sim-test-probs-SP}
\end{figure}
\begin{figure}[htp]
	\centering
	\includegraphics[width=13cm]{images/rod_MKF_test_sim_MKF_SP_x_est.pdf}
	\caption{Multi-model observer state estimates – MKF--SP}
	\label{fig:rod-obs-sim-test-x_est-SP}
\end{figure}
Figures \ref{fig:rod-obs-sim-test-probs-SP} and \ref{fig:rod-obs-sim-test-x_est-SP} show the corresponding results of simulating the sequence pruning multiple-model observer, labelled `MKF--SP', with $n_h=5$ and $N_{\text{min}}=2$, as described by \cite{eriksson_classification_1996}. Recall that in this algorithm, hypotheses are adaptively pruned and replaced at every sample time. From these plots it can be seen that the hypotheses include more possible shocks than those modelled by the sequence fusion observers with detection intervals. Also, the switching of hypothesis probabilities is swifter and distinct, and the estimation errors are visibly lower than those of both versions of the sequence fusion observer in these simulations.

To effectively evaluate and compare the performance of these observers, longer simulations with pseudo-random shocks and measurement noise are needed. Figure \ref{fig:rod-obs-sim1-ioplot} shows the first 600 input-output samples from a simulation of the system with a total duration of 2500 (5000 samples). The lower plot shows the input signals, $u(k)$ and $p(k)$, from which it can be seen that two significant random shocks occurred during this period (at $t=98$ and $220.5$). At other times, the value of $p(k)$ is a random walk due to the persistent component of the \gls{RODD} disturbance (\ref{eq:wpk2}). In addition, a step change in $u(k)$ of magnitude 1 occurred at time $t=5$. The upper plot shows the simulated output measurements. The standard deviation of the measurement noise, $\sigma_M$, was $0.1$. No disturbances other than $w_p(k)$ were simulated (i.e. $w_1(k)=0$).
\begin{figure}[htp]
	\centering
	\includegraphics[width=13cm]{images/rod_obs_sim1_all_seed_ioplot.pdf}
	\caption{Simulation of linear system with a \gls{RODD} input disturbance}
	\label{fig:rod-obs-sim1-ioplot}
\end{figure}

\subsubsection{Tuning of Kalman filters} \label{sim-obs-lin-1-KF-tuning}

Standard Kalman filters were used to develop performance baselines with which to evaluate the sub-optimal multiple-model observers. The question of how to set the gain of a Kalman filter when there is a \gls{RODD} affecting the system is open to interpretation. One naive approach is to tune the Kalman filter using the variance of the persistent component of the disturbance, $\sigma_{w_p}^2$, if it is known. In this case, the Kalman filter, which is labelled `KF1', has a noise covariance matrix
\begin{equation} \label{eq:sim-sys-siso-KF1-Q}
	\begin{aligned}
		\mathbf{Q}_{\text{KF1}}=\mathbf{Q}_0=\begin{bmatrix}
			\sigma_{x_1}^2 & 0 \\
			0 &  \sigma_{w_p}^2 \\
		\end{bmatrix}=\begin{bmatrix}
		0.1^2 & 0 \\
		0 & 0.01^2 \\
	\end{bmatrix}
	\end{aligned},
\end{equation}
where $\sigma_{x_1}^2$ is a parameter representing the variance of the errors of the process model state, $x_1(k)$. However, this leads to a filter with a slow response to shocks. The choice of $\sigma_{x_1}=0.1$ was somewhat arbitrary. In these simulations, the process is simulated by a model that is identical to the model used by the observers, so there is no model error in steady-state. However, in transient periods such as after a shock disturbance, and in real applications, errors between the observer model and the true states are expected.

A second option is to tune a Kalman filter to the variance of the infrequent shocks, $b^2\sigma_{w_p}^2$.  In this case, the Kalman filter, labelled `KF2', has a state disturbance covariance
\begin{equation} \label{eq:sim-sys-siso-KF2-Q}
	\begin{aligned}
		\mathbf{Q}_{\text{KF2}}=\mathbf{Q}_1=\begin{bmatrix}
			\sigma_{x_1}^2 & 0 \\
			0 & b^2\sigma_{w_p}^2 \\
		\end{bmatrix}=\begin{bmatrix}
			0.1^2 & 0 \\
			0 & 1^2 \\
		\end{bmatrix}.
	\end{aligned}
\end{equation}
The problem with this filter is that it is very sensitive to the measurement noise, $v(k)$. 

As explained by \cite{andersson_adaptive_1985} and \cite{robertson_detection_1995}, a trade-off is needed. One approach to making this trade-off is to minimize the average estimation errors over a suitably long set of input-output data. In this case, 5000 samples were generated from the simulated system (\ref{fig:sim-sys-diag-siso}) and then a Kalman filter was simulated multiple times, each time with a different tuning. 
\begin{figure}[htp]
	\centering
	\includegraphics[width=13cm]{images/rod_obs_sim1_3KF_Q_seed_6.pdf}
	\caption{Tuning of Kalman filter KF3 – SISO system}
	\label{fig:sim-sys-siso-KF3-tuning}
\end{figure}
Figure \ref{fig:sim-sys-siso-KF3-tuning} shows the results of these simulations, from which it can be seen that the lowest \gls{RMSE}s of the state estimates were achieved when the variance parameter $\sigma_{w_p}^2$ was close to $0.01$. Using this result, a third Kalman filter labelled `KF3' was designed with the state disturbance covariance matrix 
\begin{equation} \label{eq:sim-sys-siso-KF3-Q}
	\begin{aligned}
		\mathbf{Q}_{\text{KF3}}=\mathbf{Q}_{\text{opt}}=\begin{bmatrix}
			\sigma_{x_1}^2 & 0 \\
			0 & \sigma_{w_p,\text{opt}}^2 \\
		\end{bmatrix}=\begin{bmatrix}
			0.1^2 & 0 \\
			0 & 0.1^2 \\
		\end{bmatrix}.
	\end{aligned}
\end{equation}

Figure \ref{fig:sim-sys-siso-KF123-est} shows the estimates of the three Kalman filters described above when simulated on the input-output data. The upper plot shows the output estimates and the lower plot shows the estimates of the model state $x_{a,2}(k)$, which corresponds to the estimate of the \gls{RODD}, $p(k)$. As expected, the response of KF1 to the infrequent step disturbances is noticeably slower than that of the other two. The response of KF2 is fast, but it is sensitive to the measurement noise. KF3 is a compromise between the two—a relatively fast response to the infrequent steps and less sensitivity to the measurement noise.
\begin{figure}[htp]
	\centering
	\includegraphics[width=13cm]{images/rod_obs_sim1_all_seed_y_est1_KF123.pdf}
	\caption{Kalman filter estimates}
	\label {fig:sim-sys-siso-KF123-est}
\end{figure}

One way to visualise the observer performance is to plot the square of the output estimation errors, which are the differences between the estimates, $\hat{y}(k \mid k)$, and the true values of the system outputs, $y(k)$. The upper plot in Figure \ref{fig:sim-sys-siso-KF123-cumerr} shows the squared errors in the output estimates of the three Kalman filters. The lower plot shows the cumulative sum of the squared errors. This clearly shows the differences in performance. The estimation errors of KF1 are small when the system is in steady-state but increase dramatically after each step disturbance. The magnitude of the errors of KF2 during steady-state periods is high but roughly constant throughout the simulation. KF3 achieves the lowest overall cumulative sum-of-squared-errors by the end of the simulation.
\begin{figure}[htp]
	\centering
	\includegraphics[width=13cm]{images/rod_obs_sim1_all_seed_cum_err_y1_KF123.pdf}
	\caption{Cumulative errors of Kalman filter estimates}
	\label{fig:sim-sys-siso-KF123-cumerr}
\end{figure}

The RMSEs of the state estimates in these simulations are shown in Figure \ref{fig:rod-obs-sim1-KF123-xest-RMSE-bar}. These plots show the total RMSEs divided into two components. The blue part, labelled `no noise' is the RMSE when the system was simulated without measurement noise, (i.e. $y_M(k)=y(k)$). The orange part, labelled `due to noise' represents the difference in the RMSE between simulating with measurement noise and without. Note that this distinction is only possible with a simulation model---in real applications it is not possible to obtain the true system outputs.
\begin{figure}[htp]
	\centering
	\includegraphics[width=12cm]{images/rod_obs_sim1_all_seed_x_err_bar_KF123.pdf}
	\caption{Root-mean-squared errors of state estimates – SISO system}
	\label{fig:rod-obs-sim1-KF123-xest-RMSE-bar}
\end{figure}

As well as allowing the overall RMSE values of the three Kalman filters to be compared, these plots also illustrate the relative magnitudes of the sources of the error. As expected, the errors of KF1 are almost all due to its slow dynamic response to the shocks, whereas very little is due to the measurement noise. The opposite is true of KF2, which has a very fast dynamic response to the shocks. The trade-off between the two sources of errors is clearly illustrated for KF3. It should be noted that this may not be the best trade-off in every case. In some applications, the speed of response may be more important than the sensitivity to noise, or vice-versa. The trade-off resulting from minimizing the overall RMSE is used in this work.

\subsubsection{Selection of multiple-model observer parameters} \label{sim-obs-lin-1-MKF-tuning}

Parameter values for the sub-optimal multiple-model observer algorithms described in Section \ref{subsec-fusion} were chosen by a similar method. The sequence fusion algorithms proposed by \cite{robertson_detection_1995} and \cite{robertson_method_1998} have three parameters, \gls{nf}, \gls{m}, and \gls{d}. Candidate values for these parameters were generated by considering every combination satisfying

\begin{equation} \label{eq:sim-sys-siso-MKF-SF-param-values}
	\begin{aligned}
		\frac{N_f}{N_d} &\in \left\{3, 5, 10, 15, 20\right\},  \\
		n_\text{max} &\in \left\{1, 2, 3\right\},  \\
		N_d &\in \left\{1, 2, 3, 5, 10\right\}.
	\end{aligned}
\end{equation}

Note that $\frac{N_f}{N_d}$ represents the number of detection intervals within the fusion horizon and is always a whole number. For example, when $N_d=3$, the lengths of the fusion were 9, 15, 30, 45, and 60. However, not all combinations were simulated. Any combination with more than 200 hypotheses ($n_h>200$) or with a total probability modelled, \gls{beta} (\ref{eq:p_gamma}), less than 0.85 was rejected. The remaining 58 combinations were then evaluated by simulating the observer and calculating the \gls{RMSE} of the output estimates on the 5000 data samples from the simulated system. Tables \ref{tb:obs-sim1-popt-SF95} and \ref{tb:obs-sim1-popt-SF98} show the resulting \gls{RMSE} results for the 10 best combinations of parameter values (those with the lowest output \gls{RMSE}) for the 1995 and 1998 variants of this algorithm.

\begin{table}[ht]
	\begin{center}
		\caption{Multi-model observer parameter search results – MKF--SF95.} \label{tb:obs-sim1-popt-SF95}
		% See: https://texblog.org/2019/06/03/control-the-width-of-table-columns-tabular-in-latex/
		\begin{tabular}{p{0.05\textwidth}>{\centering\arraybackslash}p{0.07\textwidth}>{\centering\arraybackslash}p{0.07\textwidth}>{\centering\arraybackslash}p{0.07\textwidth}>{\centering\arraybackslash}p{0.07\textwidth}>{\centering\arraybackslash}p{0.24\textwidth}}
			$N_f$ & $n_\text{max}$ & $N_d$ & $n_h$ & $\beta$ & $\text{\gls{RMSE}}(\hat{Y}(N),Y(N))$  \\
			\hline
			% See script rod_obs_sim1_MKF_SF95_popt_table.m
			% 29-Nov-2022 18:35:37 results with seed = 6, sigma_M = 0.1, d_min = 1
			15 &   2 &   1 & 151 & 0.9996 & 0.0411 \\
			20 &   2 &   1 & 251 & 0.9990 & 0.0411 \\
			10 &   2 &   1 &  76 & 0.9999 & 0.0411 \\
			10 &   3 &   1 & 268 & 1.0000 & 0.0411 \\
			5 &   1 &   1 &   8 & 0.9990 & 0.0415 \\
			5 &   2 &   1 &  26 & 1.0000 & 0.0415 \\
			5 &   3 &   1 &  48 & 1.0000 & 0.0415 \\
			15 &   1 &   1 &  18 & 0.9904 & 0.0418 \\
			10 &   1 &   1 &  13 & 0.9957 & 0.0419 \\
			10 &   2 &   2 &  16 & 0.9043 & 0.0426 \\
			\hline
		\end{tabular}
	\end{center}
\end{table}

\begin{table}[ht]
	\begin{center}
		\caption{Multi-model observer parameter search results – MKF--SF98.} \label{tb:obs-sim1-popt-SF98}
		% See: https://texblog.org/2019/06/03/control-the-width-of-table-columns-tabular-in-latex/
		\begin{tabular}{p{0.05\textwidth}>{\centering\arraybackslash}p{0.07\textwidth}>{\centering\arraybackslash}p{0.07\textwidth}>{\centering\arraybackslash}p{0.07\textwidth}>{\centering\arraybackslash}p{0.07\textwidth}>{\centering\arraybackslash}p{0.24\textwidth}}
			$N_f$ & $n_\text{max}$ & $N_d$ & $n_h$ & $\beta$ & $\text{\gls{RMSE}}(\hat{Y}(N),Y(N))$  \\
			\hline
			% See script rod_obs_sim1_MKF_SF98_popt_table
			% 29-Nov-2022 18:38:45 results with seed = 6, sigma_M = 0.1, d_min = 1
			15 &   2 &   1 & 151 & 0.9996 & 0.0411 \\
			20 &   2 &   1 & 251 & 0.9990 & 0.0411 \\
			10 &   2 &   1 &  76 & 0.9999 & 0.0411 \\
			10 &   3 &   1 & 268 & 1.0000 & 0.0411 \\
			5 &   1 &   1 &   8 & 0.9990 & 0.0415 \\
			5 &   2 &   1 &  26 & 1.0000 & 0.0415 \\
			5 &   3 &   1 &  48 & 1.0000 & 0.0415 \\
			15 &   1 &   1 &  18 & 0.9904 & 0.0418 \\
			10 &   1 &   1 &  13 & 0.9957 & 0.0419 \\
			20 &   1 &   1 &  23 & 0.9831 & 0.0429 \\
			% Results with seed = 6, sigma_M = 0.3, d_min = 1
%			20 &   2 &   1 & 251 & 0.9990 & 0.1058 \\
%			15 &   2 &   1 & 151 & 0.9996 & 0.1059 \\
%			10 &   2 &   1 &  76 & 0.9999 & 0.1062 \\
%			10 &   3 &   1 & 268 & 1.0000 & 0.1062 \\
%			10 &   1 &   1 &  13 & 0.9957 & 0.1066 \\
%			15 &   1 &   1 &  18 & 0.9904 & 0.1070 \\
%			20 &   1 &   1 &  23 & 0.9831 & 0.1076 \\
%			5 &   1 &   1 &   8 & 0.9990 & 0.1106 \\
%			5 &   2 &   1 &  26 & 1.0000 & 0.1106 \\
%			5 &   3 &   1 &  48 & 1.0000 & 0.1106 \\
			\hline
		\end{tabular}
	\end{center}
\end{table}

In terms of overall estimation errors, both variants of the algorithm performed equally well in this simulation and the best combinations of parameter values are also the same. This can be attributed to the fact that in nearly all the top 10 combinations tested, the best value of the spacing parameter $N_d$ is 1. Recall that the only differences between the two variants of the algorithm are in the way the estimates are updated during the steps of the detection interval. Therefore, when $N_d=1$ the algorithms are identical. From this it may be deduced that the use of a detection interval has no benefit in this experiment. \cite{robertson_method_1998} state that their approach is a means of obtaining a long detection horizon, which is necessary when many sampling intervals are required to discriminate among various abrupt changes that may occur. On this basis, it makes sense that a long detection interval was not necessary here, since the system only has one RODD.

From a practical standpoint, it is not desirable to simulate a large number of hypotheses. On this basis, the third combination listed ($N_f=10,n_\text{max}=2,N_d=1$, requiring 76 hypotheses) or the fifth ($N_f=5,n_\text{max}=1,N_d=1$, requiring only 8 hypotheses) are good choices. The fifth combination was chosen for the simulations and the observer is labelled `MKF--SF95'. The `MKF--SF98' observer was not simulated since it provided no performance improvement over the 1995 version in this case.

The sequence pruning algorithm proposed by \cite{eriksson_classification_1996} has two parameters that must be specified, \gls{nh}, and \gls{nmin}. Candidate values for these parameters were generated by considering all combinations satisfying

\begin{equation} \label{eq:sim-sys-siso-MKF-SP-param-values}
	\begin{aligned}
		n_h &\in \left\{3, 4, 5, 7, 10, 14, 19, 25, 32\right\},  \\
			N_\text{min} &\in \left\{1, 2, 3, 4, 5, 6, 7, 9, 12, 16, 21\right\}.
	\end{aligned}
\end{equation}

Combinations where rejected when $n_h - N_\text{min} < 1$, or in other words, when the minimum life, \gls{nmin}, was greater than or equal to the number of hypotheses, \gls{nh}. This is a necessary condition since there must be enough filters to simulate the hypotheses until they exceed their minimum life. Each remaining combination was then evaluated in the same way, by calculating the \gls{RMSE} of the output estimates on the same 5000 samples used in the tuning of the sequence fusion observers described above. Table \ref{tb:obs-sim1-popt-SP} shows the top 10 combinations of parameter values in terms of lowest \gls{RMSE}.

\begin{table}[ht]
	\begin{center}
		\caption{Multi-model observer parameter search results – MKF--SP.} \label{tb:obs-sim1-popt-SP}
		% See: https://texblog.org/2019/06/03/control-the-width-of-table-columns-tabular-in-latex/
		\begin{tabular}{p{0.05\textwidth}>{\centering\arraybackslash}p{0.07\textwidth}>{\centering\arraybackslash}p{0.24\textwidth}}
			$n_h$ & $N_\text{min}$ & $\text{\gls{RMSE}}(\hat{Y}(N),Y(N))$  \\
			\hline
			% See script rod_obs_sim1_MKF_SP_popt_table.m
			% 29-Nov-2022 18:24:40 results with seed = 6, sigma_M = 0.1
			10 &   7 & 0.0409  \\
			10 &   6 & 0.0410  \\
			19 &  16 & 0.0411  \\
			14 &  12 & 0.0411  \\
			25 &  21 & 0.0411  \\
			14 &   7 & 0.0411  \\
			19 &   7 & 0.0412  \\
			19 &   6 & 0.0412  \\
			25 &  16 & 0.0412  \\
			25 &  12 & 0.0412  \\
			\hline
		\end{tabular}
	\end{center}
\end{table}

As above, the differences between the \gls{RMSE}s of the best 10 combinations are small, indicating that the choice of parameters from these combinations is not critical. The first combination ($n_h=10,N_\text{min}=7$) was chosen and the observer was labelled `MKF--SP1' in the simulations below. Table \ref{tb:obs-params-sim1} is a summary of the parameters of the observers simulated.
\begin{table}[ht]
	\begin{center}
		\caption{Observer parameters for SISO linear system.} \label{tb:obs-params-sim1}
		% See: https://texblog.org/2019/06/03/control-the-width-of-table-columns-tabular-in-latex/
		\begin{tabular}{p{0.16\textwidth}>{\centering\arraybackslash}p{0.12\textwidth}>{\centering\arraybackslash}p{0.16\textwidth}>{\centering\arraybackslash}p{0.16\textwidth}}
			& KF3 & MKF--SF95 & MKF--SP \\
			\hline
			Type & Kalman filter & Multi-model Kalman filter & Multi-model Kalman filter \\
			Algorithm & - & Sequence fusion & Sequence pruning \\
			\hline
			Parameters &  &  &  \\
			\gls{Qset} & $\mathbf{Q}_{opt}$ & $\{\mathbf{Q}_0,\mathbf{Q}_1\}$ & $\{\mathbf{Q}_0,\mathbf{Q}_1\}$ \\
			\gls{R} & $0.1^2$ & $0.1^2$ & $0.1^2$ \\
			$\mathbf{P}(0)$ & $\mathbf{P}_0$ & $\mathbf{P}_0$ & $\mathbf{P}_0$ \\
			\gls{nh} & 1 & 4 & 10 \\
			\gls{nf} & - & 5 & - \\
			\gls{m} & - & 1 & - \\
			\gls{d} & - & 1 & - \\
			\gls{nmin} & - & - & 7 \\
			\gls{epsilon} & - & 0.01 & 0.01 \\
			\gls{sigmawp} & - & 0.01 & 0.01 \\
			\gls{b} & - & 100 & 100 \\
			\hline
		\end{tabular}
	\end{center}
\end{table}

\subsubsection{Scheduled Kalman filter} \label{sim-obs-lin-1-SKF}

To determine the best performance that could be achieved by an ideal multiple-model observer, a hypothetical observer that has access to the true shock indicator signal, \gls{gammak}, was simulated. This `scheduled' Kalman filter, labelled ‘SKF’, has only one shock sequence---the correct one---and therefore the process noise covariance is automatically scheduled to match the known shock signal. The SKF is hypothetical because it could not be implemented in a real application where the random shocks are not known.

\subsubsection{Simulation results} \label{sim-obs-lin-1-results}

Figure \ref{fig:rod-obs-sim1-yest-1-SF} shows the estimates of the sequence fusion observer, MKF--SF95, compared to the scheduled Kalman Filter, SKF, over the first 600 time steps of the simulation. From these results it is apparent that the estimates of the sequence fusion observer are generally very close to those of the SKF. The estimates respond quickly when the random shocks occur and their variance at other times is relatively small despite the measurement noise. A few spontaneous errors of short duration are also noticeable in both the SKF and MKF--SF95 estimates at certain times. However, when the variances are compared to those of the Kalman filters in Figure \ref{fig:sim-sys-siso-KF123-est}, it is clear that the multiple-model observer has an advantage.
%Figure \ref{fig:rod-obs-sim1-yest-2-SF} is a closer look at the same results in the vicinity of the first step disturbance, which occurs at $t=98$.
\begin{figure}[htp]
	\centering
	\includegraphics[width=13cm]{images/rod_obs_sim1_all_seed_y_est1_SF95.pdf}
	\caption{Estimates by sequence fusion observer – SISO system}
	\label{fig:rod-obs-sim1-yest-1-SF}
\end{figure}

% Not enough space for this detailed plot
%\begin{figure}[htp]
%	\centering
%	\includegraphics[width=13cm]{images/rod_obs_sim1_all_seed_y_est2_SF95_SF98.pdf}
%	\caption{Estimates by sequence fusion observer – SISO system}
%	\label{fig:rod-obs-sim1-yest-2-SF}
%\end{figure}

Figure \ref{fig:rod-obs-sim1-yest-1-SP} shows the estimates of the sequence pruning observer, MKF--SP1, compared to the scheduled Kalman Filter. It also responds quickly to the shocks and is insensitive to the measurement noise, similar to MKF--SF95.
\begin{figure}[htp]
	\centering
	\includegraphics[width=13cm]{images/rod_obs_sim1_all_seed_y_est1_SP1.pdf}
	\caption{Estimates by sequence pruning observer – SISO system}
	\label{fig:rod-obs-sim1-yest-1-SP}
\end{figure}

% Not enough space for this detailed plot
%\begin{figure}[htp]
%	\centering
%	\includegraphics[width=13cm]{images/rod_obs_sim1_all_seed_y_est2_SP1.pdf}
%	\caption{Estimates by sequence pruning observer – SISO system}
%	\label{fig:rod-obs-sim1-yest-2-SP}
%\end{figure}

The plots in Figure \ref{fig:rod-obs-sim1-cum-err-y1-all} show the squared output errors and the cumulative squared-errors of four observers over the full duration of the simulation. The differences between the two multiple-model observers is almost indistinguishable. By the end of the simulation, the cumulative errors are significantly lower than those of KF3 and slightly higher than the SKF.
\begin{figure}[htp]
	\centering
	\includegraphics[width=13cm]{images/rod_obs_sim1_all_seed_cum_err_y1.pdf}
	\caption{Cumulative errors of observer estimates – SISO system}
	\label{fig:rod-obs-sim1-cum-err-y1-all}
\end{figure}

Figure \ref{fig:rod-obs-sim1-xest-RMSE-bar} compares the \gls{RMSE}s of the state estimates of the five observers over the full simulation. From this it can be seen that the multiple-model observers achieve lower RMSEs than KF3 in simulations with and without noise, although the reduction in the errors due to the lower sensitivity to measurement noise (orange bars) is a more significant contribution. It is noteworthy that most of the errors of the estimates in state 2, which corresponds to the input disturbance, are not due to measurement noise. These may partly be attributed to the delay in the process, which makes it impossible for the observers to immediately detect the unmeasured disturbances. They are also due to errors in tracking the persistent component of the disturbance, which can be seen in Figures \ref{fig:rod-obs-sim1-yest-1-SF} and \ref{fig:rod-obs-sim1-yest-1-SP}.
\begin{figure}[htp]
	\centering
	\includegraphics[width=12cm]{images/rod_obs_sim1_all_seed_x_err_bar.pdf}
	\caption{Root-mean-squared errors of state estimates – SISO system}
	\label{fig:rod-obs-sim1-xest-RMSE-bar}
\end{figure}

Because these processes are stochastic, it is important to run simulations of sufficient duration to be confident that the results are representative of average performance. Figure \ref{fig:rod-obs-sim1-yest-all-seed-RMSE-box} provides an indication of the sensitivity of the \gls{RMSE} results to the initialization of the pseudo-random number generator used in these simulations. The data for this figure are the results of 10 different simulations, each of 5000 samples and with a different pseudo-random initialization. It can be seen that the \gls{RMSE} values are somewhat sensitive to the random initialization but the variation is an order of magnitude lower than the difference between the multiple model observers and KF3.
\begin{figure}[htp]
	\centering
	\includegraphics[width=12cm]{images/rod_obs_sim1_all_seed_y_err_box.pdf}
	\caption{Sensitivity of output estimation errors to random initialization – SISO system}
	\label{fig:rod-obs-sim1-yest-all-seed-RMSE-box}
\end{figure}
Figure \ref{fig:rod-obs-sim1-yest-all-seed-RMSE-box} confirms that the multiple-model observers are a significant improvement on the best single Kalman filter. However, there is no significant difference between the two MKFs in this case.
% Plots for analysis of SF performance
%
%\begin{figure}[htp]
%	\centering
%	\includegraphics[width=15cm]{images/rod-obs-sim-1-4-wfplot-DRAFT.png}
%	\caption{Evolution of conditional probabilities with sequence fusion}
%	\label{fig:rod-obs-sim1-4-wfplot}
%\end{figure}
%
%\begin{figure}[htp]
%	\centering
%	\includegraphics[width=14cm]{images/rod-obs-sim-1-4-est-MKF-SF-plot-DRAFT.pdf}
%	\caption{Filter estimates of sequence fusion observer during step disturbances}
%	\label{fig:rod-obs-sim1-4-est-MKF-SF-plot-DRAFT}
%\end{figure}
%
%\begin{figure}[htp]
%	\centering
%	\includegraphics[width=14cm]{images/rod_obs_sim2_7_mse_ashocks.pdf}
%	\caption{Average errors of observer estimates after shock disturbances}
%	\label{fig:rod_obs_sim2_7_mse_ashocks}
%\end{figure}

\subsection{MIMO linear system} \label{sim-obs-lin-2}

\cite{robertson_method_1998} stated that in the case of more than one RODD disturbance, it often takes many sampling intervals to discriminate among possible disturbances. The main motivation for the detection intervals used in their approach was to achieve a longer \textit{detection horizon} without requiring a very large number of hypotheses. To evaluate this feature, a \textit{multiple-input, multiple-output} (MIMO) system with a 2-input, 2-output ($2\times2$) process model was chosen. The system has two independent \gls{RODD} step disturbances added to each manipulated input, as shown in the functional diagram in Figure \ref{fig:sim-sys-diag-2x2}. 
\begin{figure}[htp]
	\centering
	\includegraphics[width=11.5cm]{images/sim-sys-diag-2x2.pdf}
	\caption{Functional diagram of the simulated MIMO system}
	\label{fig:sim-sys-diag-2x2}
\end{figure}

The process model is a discrete-time linear model derived from the $2\times2$ continuous-time system,
% 2x2 system #1 - see sys_rodin_step_2x2sym.m
%\begin{equation} \label{eq:sim-sys-mimo-ct}
%	\mathbf{G}(s) = \left[\begin{array}{cc}
%		G_{11}(s) & G_{12}(s)  \\
%		G_{21}(s) & G_{22}(s)  \\
%	\end{array}\right] = \left[\begin{array}{cc}
%		\frac{1}{1+8.5s} & \frac{-0.5}{1+8.5s}  \\
%		\frac{-0.5}{1+8.5s} & \frac{1}{1+8.5s}  \\
%	\end{array}\right]
%\end{equation}
% 2x2 system #2 - see sys_rodin_step_2x2sym2.m
\begin{equation} \label{eq:sim-sys-mimo-ct}
	\mathbf{G}(s) = \left[\begin{array}{cc}
		G_{11}(s) & G_{12}(s)  \\
		G_{21}(s) & G_{22}(s)  \\
	\end{array}\right] = \left[\begin{array}{cc}
		\frac{1}{1+8.5s} & \frac{0.5}{1+8.5s}  \\
		\frac{0.5}{1+8.5s} & \frac{1}{1+8.5s}  \\
	\end{array}\right],
\end{equation}
where $s$ is the Laplace variable.  This model was chosen because the dynamics of each input-output combination are similar (they have the same time constant and the sign of the gain is the same). The only differences are in the magnitude of the static gains. The model was converted to a discrete-time model with a sampling period of 1. The discrete-time state space model of the augmented system used by the observers was
\begin{equation} \label{eq:sim-sys-2x2-ss-aug}
	\begin{split}
		\mathbf{x}_{a}(k+1) & =\left[\begin{array}{cccc}
			0.8890 & 0 & 1 & 0.5 \\
			0 & 0.8890 & 0.5 & 1 \\
			0 & 0 & 1 & 0 \\
			0 & 0 & 0 & 1
		\end{array}\right] \mathbf{x}_{a}(k) + \left[\begin{array}{cc}
			1 & 0.5 \\
			0.5 & 1
		\end{array}\right] \mathbf{u}(k) + \mathbf{w}_{a}(k) \\
		y(k) & =\left[\begin{array}{cccc}
			0.1110 & 0 & 0 & 0 \\
			0 & 0.1110 & 0 & 0
		\end{array}\right] \mathbf{x}_{a}(k) + v(k)
	\end{split}
\end{equation}
where
\begin{equation} \label{eq:sim-sys-2x2-ss-aug2}
	\mathbf{x}_{a}(k) = \left[\begin{array}{l}
		x_{1}(k) \\
		x_{2}(k) \\
		p_{1}(k) \\
		p_{2}(k)
	\end{array}\right], \mathbf{w}_{a}(k) = \left[\begin{array}{l}
		w_1(k) \\
		w_2(k) \\
		w_{p,1}(k) \\
		w_{p,2}(k)
	\end{array}\right].
\end{equation}

Note that with this representation, the third and fourth model states, $x_{a,3}(k)$ and $x_{a,4}(k)$, correspond exactly to the two input disturbances, $p_1(k)$ and $p_2(k)$.

The two random shocks were simulated with the same parameters as those in the SISO simulation, $\epsilon_i=0.01, \sigma_{w_{p,i}}=0.01$, and $b_i=100$. However, the standard deviations of the measurement noises, $\sigma_{M,1}$ and $\sigma_{M,2}$, were $0.2$, which is twice as high as it was for the SISO simulations, and the sampling period was double ($T_s=1$).

Figure \ref{fig:rod-obs-sim-2-ioplot} shows the first 300 input-output samples from a simulation of the system with a total duration of 5000. The lower of the two plots shows the input signals, $u_1(k)$, $u_2(k)$, $p_1(k)$, and $p_2(k)$. In this simulation, there were no changes to the known input variables. The upper plot shows the simulated output measurements, $y_1(k)$ and $y_2(k)$. No input disturbances other than $w_{p,1}(k)$ and $w_{p,2}(k)$ were simulated (i.e. $w_1(k)=w_2(k)=0$).
\begin{figure}[htp]
	\centering
	\includegraphics[width=13cm]{images/rod_obs_sim3_all_seed_ioplot.pdf}
	\caption{Simulation of linear MIMO system with two \gls{RODD}s}
	\label{fig:rod-obs-sim-2-ioplot}
\end{figure}

As in the previous experiment, a standard Kalman filter was tuned experimentally to achieve a low \gls{RMSE} of the output estimates. The details of this tuning process are included in Annex \ref{section:annex-sim-2-KF-tuning} including the resulting value of $\mathbf{Q}_{\text{KF3}}$ (\ref{eq:sim-sys-sim3-KF3-Q}).


\subsubsection{Selection of multiple-model observer parameters}

Parameter values for the sub-optimal multiple-model observers were chosen by a similar method to that of the SISO experiment. The details of the parameter search and selection process are in Annex \ref{section:annex-sim-2-MKF-tuning}. As in the SISO experiment, the 1998 version of the sequence fusion algorithm did not offer an improvement on the performance of the 1995 version. The best performance of the 1998 version was obtained when the length of the detection interval was 1, which means it is no different than the 1995 version. Nevertheless, this time it was included in the simulations for comparison and labelled `MKF--SF2'. Table \ref{tb:obs-params-sim2} summarises the observer parameters used in the simulations.
\begin{table}[ht]
	\begin{center}
		\caption{Observer parameters for MIMO linear system.} \label{tb:obs-params-sim2}
		% See: https://texblog.org/2019/06/03/control-the-width-of-table-columns-tabular-in-latex/
		\begin{tabular}{p{0.16\textwidth}>{\centering\arraybackslash}p{0.12\textwidth}>{\centering\arraybackslash}p{0.16\textwidth}>{\centering\arraybackslash}p{0.16\textwidth}>{\centering\arraybackslash}p{0.16\textwidth}}
			& KF3 & MKF--SF95 & MKF--SF2 & MKF--SP1 \\
			\hline
			Type & Kalman filter & Multi-model Kalman filter & Multi-model Kalman filter & Multi-model Kalman filter \\
			Algorithm & - & Sequence fusion 95 & Sequence fusion 98 & Sequence pruning \\
			\hline
			Parameters &  &  & &  \\
			\gls{Qset} & $\mathbf{Q}_{opt}$ & $\{\mathbf{Q}_0,\mathbf{Q}_1\}$ & $\{\mathbf{Q}_0,\mathbf{Q}_1\}$ & $\{\mathbf{Q}_0,\mathbf{Q}_1\}$ \\
			\gls{R} & $\left[\begin{smallmatrix}0.2^2 & 0 \\ 0 & 0.2^2\end{smallmatrix}\right]$
			& $\left[\begin{smallmatrix}0.2^2 & 0 \\ 0 & 0.2^2\end{smallmatrix}\right]$
			& $\left[\begin{smallmatrix}0.2^2 & 0 \\ 0 & 0.2^2\end{smallmatrix}\right]$
			& $\left[\begin{smallmatrix}0.2^2 & 0 \\ 0 & 0.2^2\end{smallmatrix}\right]$ \\
			$\mathbf{P}(0)$ & $\mathbf{P}_0$ & $\mathbf{P}_0$ & $\mathbf{P}_0$ & $\mathbf{P}_0$ \\
			\gls{nh} & 1 & 116 & 116 & 46 \\
			\gls{nf} & - & 15 & 10 & - \\
			\gls{m} & - & 2 & 2 & - \\
			\gls{d} & - & 3 & 2 & - \\
			\gls{nmin} & - & - & - & 21 \\
			\gls{epsilon} & - & $\begin{bsmallmatrix}0.01 & 0.01\end{bsmallmatrix}^\intercal$
			& $\begin{bsmallmatrix}0.01 & 0.01\end{bsmallmatrix}^\intercal$ 
			& $\begin{bsmallmatrix}0.01 & 0.01\end{bsmallmatrix}^\intercal$ \\
			\gls{sigmawp} & - & $\begin{bsmallmatrix}0.01 & 0.01\end{bsmallmatrix}^\intercal$
			& $\begin{bsmallmatrix}0.01 & 0.01\end{bsmallmatrix}^\intercal$ 
			& $\begin{bsmallmatrix}0.01 & 0.01\end{bsmallmatrix}^\intercal$ \\
			\gls{b} & - & $\begin{bsmallmatrix}100 & 100\end{bsmallmatrix}^\intercal$
			& $\begin{bsmallmatrix}100 & 100\end{bsmallmatrix}^\intercal$ 
			& $\begin{bsmallmatrix}100 & 100\end{bsmallmatrix}^\intercal$ \\
			\hline
		\end{tabular}
	\end{center}
\end{table}

\subsubsection{Simulation Results}

Figure \ref{fig:rod-obs-sim2-yest-1-SF} shows the estimates of both sequence fusion observers (MKF--SF95 and MKF--SF2) compared to the scheduled Kalman Filter (SKF) over the first 300 time steps of the simulation. The upper two plots show the estimates of outputs 1 and 2 compared to the true system outputs. The lower two plots show the estimates of states 3 and 4, which correspond to the input disturbances. The largest errors occur in the periods following the shocks. At these times, the estimates of MKF--SF2 lag those of MKF--SF95, and MKF--SF95 lags those of the SKF. At other times, the estimates of all three observers are quite similar, although MKF--SF95 seems to have a slightly higher variance.
\begin{figure}[htp]
	\centering
	\includegraphics[width=13cm]{images/rod_obs_sim3_all_seed_y_est1_SF95_SF2.pdf}
	\caption{Estimates by sequence fusion observer –  $2\times2$ system}
	\label{fig:rod-obs-sim2-yest-1-SF}
\end{figure}

Figure \ref{fig:rod-obs-sim2-yest-1-SP} shows the estimates of the sequence pruning observer (MKF--SP) compared to the scheduled Kalman Filter on the same the simulation data. The behaviour is similar to that of MKF--SF95, matching SKF during the periods between shocks and lagging it in the periods immediately after shocks.
\begin{figure}[htp]
	\centering
	\includegraphics[width=13cm]{images/rod_obs_sim3_all_seed_y_est1_SP1.pdf}
	\caption{Estimates by sequence pruning observer –  $2\times2$ system}
	\label{fig:rod-obs-sim2-yest-1-SP}
\end{figure}

%\begin{figure}[htp]
%	\centering
%	\includegraphics[width=13cm]{images/rod_obs_sim2_all_seed_y_est2_MKF.pdf}
%	\caption{Comparison of multiple-model observer estimates –  $2\times2$ system}
%	\label{fig:rod-obs-sim2-yest-2-MKF}
%\end{figure}
Figure \ref{fig:sim-sys-sim2-MKF-cumerr} shows the squared output errors and the cumulative squared-errors of the five observers over the full simulation. This reveals that on average, the MKF--SF95 observer performs better than the other two multiple-model observers. The cumulative errors by the end of the simulation are still significantly lower than those of KF3 but not as close to those of the SKF as they were in the SISO system simulation.
\begin{figure}[htp]
	\centering
	\includegraphics[width=13cm]{images/rod_obs_sim3_all_seed_cum_err_y2.pdf}
	\caption{Cumulative sum of squared errors of output estimates –  $2\times2$ system}
	\label{fig:sim-sys-sim2-MKF-cumerr}
\end{figure}

% Replaced with above single plot to save space
%\begin{figure}[htp]
%	\centering
%	\includegraphics[width=13cm]{images/rod_obs_sim2_cum_err2.pdf}
%	\caption{Cumulative errors of multiple-model observer output estimates –  $2\t_y2mes2$ system}
%	\label{fig:sim-sys-sim2-MKF-cumerr2}
%\end{figure}
%\begin{figure}[htp]
%	\centering
%	\includegraphics[width=11cm]{images/rod_obs_sim2_all_seed_x_err_bar.pdf}
%	\caption{Root-mean-squared errors of state estimates – $2\times2$ system}
%	\label{fig:rod-obs-sim2-xest-RMSE-bar}
%\end{figure}
As in the SISO case, 10 different simulations were carried out with different random initializations to check the sensitivity of the results. Figure \ref{fig:rod-obs-sim2-yest-all-seed-RMSE-box} shows the variation in the RMSE results. This confirms that the performance of the three multiple model observers is quite similar but MKF--SF95 achieves a slightly lower error on average.
\begin{figure}[htp]
	\centering
	\includegraphics[width=11cm]{images/rod_obs_sim3_all_seed_y_err_box.pdf}
	\caption{Root-mean-squared errors of output estimates – $2\times2$ system}
	\label{fig:rod-obs-sim2-yest-all-seed-RMSE-box}
\end{figure}

\section{Grinding process simulation} \label{section:sim-ore-SISO}

In this section, results of an experiment to test the observers with data from the grinding process simulator are presented. This work is an extension of previously published work \citep{tubbs_observer_2022}. In the original work, a multiple model observer with sequence pruning was tested. In this work, both types of multiple model observer are evaluated and compared (sequence fusion and sequence pruning). Also, in this work, Kalman filters in filtering form are used, whereas in the previous work the prediction form (\ref{eq:xkp1_hat_p}) was used.

For the purposes of this experiment, the size of the ground product leaving the cyclone overflow is sampled every 3 minutes and a zero-mean Gaussian measurement noise with a standard deviation of 5 $\mu\text{m}$ is added directly to the simulation output. No other known inputs are available to the observer.

\subsection{System Identification} \label{section-sysid}

Model-based observers such as the Kalman filter require a dynamic model of the process. In practice, models of the process dynamics are not available and must be identified from operating data. Here, a single-input, single-output (SISO) process model is considered with a RODD step disturbance at the input, as shown in Figure \ref{fig:grind1_obs_model}. 
\begin{figure}[ht]
	\centering
	\includegraphics[width=8.5cm]{images/grind1-obs-model-diag.pdf}
	\caption{Observer model structure}
	\label{fig:grind1_obs_model}
\end{figure}

The disturbance, $p(k)$, represents step changes in the ore mix factor, as described in Section \ref{sec:grinding-simulator}. The output variable, $y(k)$, is the product P80. $v(k)$ is an additive measurement noise.

To construct a multi-model observer for this system, the structure and parameters of the process model as well as the disturbance model are needed. As mentioned in the previous chapter, standard system identification techniques such as linear regression are not suitable for estimating hybrid dynamical systems with discrete states.

To avoid this problem, it is assumed here that the time and magnitude of the ore changes can be determined for a period of time sufficient for system identification. This could be the case when analysis of samples of ore is possible but too costly to continuously in normal operation.

Or when stocks of ores with well-known properties can be fed to the mill in a controlled manner. It is also assumed that the structure of the RODD model (\ref{eq:RODD}) is known, and that values for the parameters $\sigma_{w_p}$, $b$ and $\epsilon$ are available.

In practice, $\epsilon$ could potentially be estimated from historic operating data by simply counting the number of ore changes in a sufficiently long period and dividing by the number of sample periods, although this method is somewhat inaccurate because small shocks are undetectable in noisy data. Estimating $b$$\sigma_{w_p}$ may require prior knowledge of the P80 of the ores, from geological data or periodic testing.

%An approximate model can be identified from process measurements using system identification as described by \cite{ljungSystemIdentification1999} and others.
%To mimic a realistic system identification exercise, three independent data acquisition experiments, each of 15 hours duration, were simulated using the grinding simulation model described in Section \ref{section-simulator}. During each, a random binary sequence of step changes in the ore mix factor was introduced. The process was at steady-state at the beginning of each sequence and the first 3 hours of data (60 samples) were used to estimate the steady-state values of the process variables.
Figure \ref{fig:sim_ioplots} shows the input-output data used for estimation of the process model.

Outline notes:
\begin{outline}
	\1 Unlike previous simulations, this is a non-linear model.
	\1 Describe simulations with grinding simulation model with changing ore properties and changes (same as IFAC paper).
	\1 Describe various data sets generated and their intended use (estimation, validation, statistical performance evaluation).
	\1 Data set used for model identification in Figure: Input-output data – Figure \ref{fig:rod_obs_sim_1_ioplot_P2DcTd4}.
	\1 How process model was identified.
	\1 Augmented model with \gls{RODD} input step disturbance.
	\1 Use best observer from previous section (sequence pruning).
	\1 Table showing observer parameters.
	\1 Figure: comparison of observer estimates – Figure \ref{fig:rod_obs_sim_1_est_P2DcTd4}.
	\1 Figure: Observer responses to disturbances – Figure \ref{fig:sim_resp_plot}.
	\1 Describe overall performance comparison using metrics in Table \ref{tb:results}.
	\1 Discuss pro's and con's of MKF observer (steady-state errors vs error in transitions, etc.)
	\1 Discuss applications and potential benefits (e.g. process control, RTO).
	\1 Describe sensitivity analysis simulations.
	\1 Describe sensitivity results:
	\2 (1) to model error, compare Kalman filter and MKF. Figures \ref{fig:rod_obs_sim_sens_model_KF2_MSE_y_est} and \ref{fig:rod_obs_sim_sens_model_MKF_MSE_y_est}.
	\2 (2) MKF sensitivity to \gls{RODD} model parameters. Figure  \ref{fig:rod_obs_sim_sens_rod_MKF_MSE_y_est}
\end{outline}

\begin{figure}[htp]
	\centering
	\includegraphics[width=12cm]{images/rod_obs_sim_1_ioplot_P2DcTd4.pdf}
	\caption{Grinding process simulation data and model estimates}
	\label{fig:rod_obs_sim_1_ioplot_P2DcTd4}
\end{figure}

\begin{figure}[htp]
	\centering
	\includegraphics[width=12cm]{images/rod_obs_sim_1_est_P2DcTd4.pdf}
	\caption{Observer estimates}
	\label{fig:rod_obs_sim_1_est_P2DcTd4}
\end{figure}

\begin{figure}[htp]
	\centering
	\includegraphics[width=12cm]{images/sim_resp_plot1_P2DcTd4.pdf}
	\caption{Average observer responses to step disturbances}
	\label{fig:sim_resp_plot}
\end{figure}

\begin{table}[ht]
	\begin{center}
		\caption{Observer performance evaluation metrics.} \label{tb:results}
		% See: https://texblog.org/2019/06/03/control-the-width-of-table-columns-tabular-in-latex/
		\begin{tabular}{p{0.34\textwidth}>{\centering\arraybackslash}p{0.09\textwidth}>{\centering\arraybackslash}p{0.09\textwidth}>{\centering\arraybackslash}p{0.09\textwidth}>{\centering\arraybackslash}p{0.11\textwidth}>{\centering\arraybackslash}p{0.09\textwidth}}
			Metric & KF1 & KF2 & KF3 & MKF-SP & SKF \\
			\hline
			MSE($\hat{y}(k),y(k)$) overall          & 11.0 & 15.9 & 3.7 & 3.5 & 2.1 \\ 
			MSE($\hat{y}(k),y(k)$) transient       & 21.1 & 16.1 & 7.7 & 11.2 & 5.1 \\ 
			MSE($\hat{y}(k),y(k)$) steady-state & 7.9 & 15.9 & 2.5 & 1.1 & 1.1 \\ 
			Var($\hat{y}(k)$) steady-state          & 1.8 & 15.3 & 1.9 & 0.5 & 0.2 \\ 
			MSD($\hat{y}(k),y(k)$) steady-state       & 0.0 & 16.2 & 0.5 & 0.2 & 0.0 \\ 
			% Results for P2DcTd4
			%  Gc = -32.4 * exp(-0.2 * s) / (1 + 0.106*s)^2;
			%                                 KF1       KF3       AFMM        SKF  
			%  MSE                         11.118    3.7395     3.6991     2.0615
			%  MSE in transitions          20.687    7.7201      12.18     5.0674
			%  MSE in steady-state         8.1885     2.521     1.1028     1.1414
			%  Variance in steady-state    1.7723    1.9026    0.39281    0.23769
			%
			% Results for P2Dcd1_T
			%  Gc = -35.94 * exp(-0.05 * s) / ((1 + 0.235*s) * (1 + 0.161*s));
			%                                 KF1       KF3       AFMM        SKF  
			%  MSE                         10.707    3.7702     3.7283     1.9652
			%  MSE in transitions          21.052    7.7605     12.397     4.8145
			%  MSE in steady-state         7.5404    2.5486     1.0745      1.093
			%  Variance in steady-state    1.8111    1.9259    0.39282    0.24514
			
			% Updated results for P2DcTd4 with n_filt = 20, n_min = 18 after fixing
			% initialization between MC simulation runs.
			%  MSE                          11.01    3.6869     3.4952     1.8191
			%  MSE in transitions          21.137    7.7201     11.208     5.0722
			%  MSE in steady-state         7.9091    2.4523     1.1342     0.8232
			%  Variance in steady-state    1.8008    1.9026    0.47604    0.23759
			
			\hline
		\end{tabular}
	\end{center}
\end{table}

\begin{figure}[htp]
	\centering
	\includegraphics[width=12cm]{images/rod_obs_sim_sens_model_KF2_MSE_y_est.pdf}
	\caption{Sensitivity of KF2 estimates to changes in model parameters}
	\label{fig:rod_obs_sim_sens_model_KF2_MSE_y_est}
\end{figure}

\begin{figure}[htp]
	\centering
	\includegraphics[width=12cm]{images/rod_obs_sim_sens_model_MKF_MSE_y_est.pdf}
	\caption{Sensitivity of \gls{MKF} observer estimates to changes in model parameters}
	\label{fig:rod_obs_sim_sens_model_MKF_MSE_y_est}
\end{figure}

\begin{figure}[htp]
	\centering
	\includegraphics[width=12cm]{images/rod_obs_sim_sens_rod_MKF_MSE_y_est.pdf}
	\caption{Sensitivity of \gls{MKF} observer estimates to changes in \gls{RODD} parameters}
	\label{fig:rod_obs_sim_sens_rod_MKF_MSE_y_est}
\end{figure}


\section{Grinding circuit control simulation} \label{section:sim-ore-mimo-ctrl} 

Outline notes:
\begin{itemize}
	\item Grinding simulation model in closed loop with \gls{MPC} controller.
	\item Diagram of feedback system – Figure \ref{fig:sim-mpc-diag}
	\item Table of results - Performance metrics — e.g. tracking error.
	\item Robustness?  E.g. stability margins.
\end{itemize}

\begin{figure}[htp]
	\centering
	\includegraphics[width=11cm]{images/sim-mpc-diag.pdf}
	\caption{Functional diagram of the simulated feedback control system}
	\label{fig:sim-mpc-diag}
\end{figure}

\begin{figure}[htp]
	\centering
	\includegraphics[width=15.5cm]{images/mpc4x4_stepresp_matrix.pdf}
	\caption{Step responses of identified input-output model}
	\label{fig:mpc4x4-stepresp-matrix}
\end{figure}

