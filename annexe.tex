\chapter{Additional results and sensitivity analysis}     % numérotée
\label{chap-Annex}                   % étiquette pour renvois (à compléter!)

\section{Multiple model observer algorithms}

\begin{itemize}
	\item Multi-model algorithm.
\end{itemize}

\section{Tuning of sequence fusion algorithm 1995 variant}

The sequence fusion algorithm evaluated in section \ref{section:sim-obs-lin} is based on \cite{robertson_method_1998}. However, Robertson and coworkers published results in 1995 \citep{robertson_detection_1995} using a slightly different version of this algorithm. Table \ref{tb:obs-sim1-popt-SF95} shows the results of a parameter search for the earlier version of the algorithm using the same simulation data used to tune the 1998 algorithm.

\begin{table}[hb]
	\begin{center}
		\caption{Multi-model observer parameter search results – MMKF-SF95.} \label{tb:obs-sim1-popt-SF95}
		% See: https://texblog.org/2019/06/03/control-the-width-of-table-columns-tabular-in-latex/
		\begin{tabular}{p{0.05\textwidth}>{\centering\arraybackslash}p{0.07\textwidth}>{\centering\arraybackslash}p{0.07\textwidth}>{\centering\arraybackslash}p{0.07\textwidth}>{\centering\arraybackslash}p{0.07\textwidth}>{\centering\arraybackslash}p{0.24\textwidth}}
			$n_f$ & $n_m$ & $n_d$ & $n_h$ & $\beta$ & $\text{RMSE}(\hat{Y}_i(N),Y_i(N))$  \\
			\hline
			% Results with seed = 6, nT = 5000
			15 &   1 &   3 &   6 & 0.9035 & 0.1156 \\
			15 &   2 &   3 &  16 & 0.9044 & 0.1156 \\
			15 &   3 &   3 &  26 & 0.9044 & 0.1156 \\
			15 &   1 &   1 &  16 & 0.9904 & 0.1168 \\
			15 &   2 &   1 & 121 & 0.9996 & 0.1168 \\
			15 &   1 &   5 &   4 & 0.8861 & 0.1186 \\
			15 &   2 &   5 &   7 & 0.8864 & 0.1186 \\
			15 &   3 &   5 &   8 & 0.8864 & 0.1186 \\
			9 &   3 &   3 &   8 & 0.9415 & 0.1188 \\
			9 &   2 &   3 &   7 & 0.9415 & 0.1188 \\
			\hline
		\end{tabular}
	\end{center}
\end{table}

From these results it can be seen that the parameter tunings are quite similar to those in Table \ref{tb:obs-sim1-popt-SF} for the 1998 variant of the algorithm. However, the best RMSE value achieved by the 1995 algorithm (0.1156) is slightly higher than the best achieved by the 1998 variant (0.1089) in this case.

Figure \ref{fig:rod-obs-sim1-yest-all-seed-RMSE-box-SF95} shows the results of both observers on different pseudo-random simulation results. This supports the finding by Robertson et al. that the 1998 variant of the algorithm performs better.

\begin{figure}[htp]
	\centering
	\includegraphics[width=12cm]{images/rod_obs_sim1_all_seed_y_err_box_SF95.pdf}
	\caption{Comparison of sequence fusion algorithm variants}
	\label{fig:rod-obs-sim1-yest-all-seed-RMSE-box-SF95}
\end{figure}



\section{Tuning of KF3 for MIMO linear system} \label{section:annex-sim-2-KF-tuning}

As described in Chapter \ref{chap-simulation}, a standard Kalman filter was tuned to minimize the RMSE of the output estimates using 5000 data samples from the $2\times2$ linear system. Since the system is symmetrical and the two RODDs have the same parameters, it was assumed that the two observer parameters, $\sigma_{w_p,1,\text{opt}}$ and $\sigma_{w_p,2,\text{opt}}$ must also be identical. This assumption simplified the search process since only one optimum value needed to be found.

Figure \ref{fig:sim-sys-2x2-KF3-tuning-sens} shows the variation in the RMSEs of the four model state estimates with the parameters. In this case, the choice of optimal parameter value was not as straight-forward as in the case of the SISO system with one RODD. The minimum RMSE for each state occurs at different values of  1 and 2 is achieved when $\sigma_{w_p,1,\text{opt}}=\sigma_{w_p,2,\text{opt}}=0.0075$

\begin{figure}[htp]
	\centering
	\includegraphics[width=14cm]{images/rod_obs_sim2_3KF_Q_seed_0.pdf}
	\caption{Tuning of Kalman filter KF3 – $2\times2$ system}
	\label{fig:sim-sys-2x2-KF3-tuning}
\end{figure}
	

\section{Sensitivity analyses}

\subsection{Pseudo-random numbers}

Many of the simulation results are sensitive to the initialization of the pseudo-random number generator (PRNG) used to simulate random processes. In particular, the RODD step disturbance (\ref{eq:wpk2}) is simulated by generating three pseudo-random sequences, two random noise sequences and a random binary sequence to simulate the infrequent shocks.  Since the random shocks are infrequent and tend to have a large magnitude, their effect on the simulation results can be significant.

To visualize this effect, consider the plot in Figure \ref{fig:rod-obs-sim-1-3KF-seed-crmse-statsplot}. This shows the RMSE of the output estimates of the three Kalman filters described in Section \ref{sim-obs-lin-1} for 10 simulations, each generated with a different \textit{seed}—the seed is a scalar argument used to initialize the PRNG algorithm in a unique state. The RMSE is calculated for every simulation duration, $t_N=0.5,1,1.5,...,2500$. The coloured areas represent the range between the lowest and the highest RMSE obtained for the 10 different simulations of each duration. The dark lines represent the median values.

\begin{figure}[htp]
	\centering
	\includegraphics[width=14cm]{images/rod_obs_sim1_3KF_seed_crmse_statsplot.pdf}
	\caption{Effect of random variables on the RMSE results.}
	\label{fig:rod-obs-sim-1-3KF-seed-crmse-statsplot}
\end{figure}

As expected, the differences in the results due to PRNG initialization are smaller the greater the length of the simulation. However, the magnitude of the differences is not the same for each observer. The RMSE values of KF1, which has the lowest gain, are more sensitive to the random initialization than the other two filters. Therefore it is not possible to estimate the expected value of the RMSE of KF1 from a single simulation of this duration---a longer simulation or a larger number of simulations would be needed. On the other hand, the variations in the RMSEs of KF2 and KF3 are significantly lower. After the full length of the simulations ($t_N=2500$), the RMSE of KF2 is between -0.0039 (-2.5\%) and 0.0019 (1.3\%) of the median value, which is $0.1550$.  That of KF3 is between -0.0035 (-4.0\%) / 0.0047 (5.3\%) of the median, 0.0889.  Therefore it is reasonable to conclude that the RMSE of KF3 is consistently about 0.05 lower than that of KF2. Note that the RMSEs of KF2 and KF3 reported in Section \ref{sim-obs-lin-1} are \alert{0.XXXX} and \alert{0.XXXX}. These values are both within the minimum and maximum values from this sensitivity analysis (in fact, the simulation output used to produce the main results is one of the 10 shown here).

A similar sensitivity analysis was carried out on the results of the Kalman Filter tuning shown in Figure \ref{eq:sim-sys-siso-KF3-Q}, where KF3 was tuned using a set of 5000 input-output samples from the system. Figure \ref{fig:sim-sys-siso-KF3-sensitivity} shows the variation in this result when ten different sets of pseudo-random simulation data are used.  Although there is considerable variation in the RMSE values for each parameter value, the best overall choice of $\sigma_{w_p}$ to achieve the lowest average error across all 10 simulations was found to be the same as that of the single simulation (0.01).

\begin{figure}[htp]
	\centering
	\includegraphics[width=14cm]{images/rod_obs_sim1_3KF_Q_statplot.pdf}
	\caption{Sensitivity of Kalman filter tuning – SISO system}
	\label{fig:sim-sys-siso-KF3-sensitivity}
\end{figure}

Figure \ref{fig:sim-sys-2x2-KF3-tuning-sens} shows the results of a similar sensitivity analysis on the results presented in Figure \ref{fig:sim-sys-2x2-KF3-tuning}.

\begin{figure}[htp]
	\centering
	\includegraphics[width=14cm]{images/rod_obs_sim2_3KF_Q_statplot.pdf}
	\caption{Sensitivity of Kalman filter tuning – $2\times2$ system}
	\label{fig:sim-sys-2x2-KF3-tuning-sens}
\end{figure}

