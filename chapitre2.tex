% !TEX encoding = UTF-8 Unicode
\chapter{Methods}
\label{chap-methods}


\section{Disturbance models}

\subsection{Randomly-occurring deterministic disturbances} \label{sec:RODD}

\textit{Randomly-occurring deterministic disturbances} (\gls{RODD}s) \citep{macgregor_duality_1984} are a family of stochastic process models suitable for simulating various types of infrequently-occurring disturbances in discrete-time.  The structure of the \gls{RODD} model is
\begin{equation} \label{eq:RODD}
	p(k)= \frac{B(q^{-1})}{A(q^{-1})}\gls{wpk},
\end{equation}
where \gls{pk} is the generated disturbance signal, $A(q^{-1})$ and $B(q^{-1})$ are arbitrary polynomial functions of the backward shift operator, \gls{qm1}, and \gls{wpk} is a random variable generated by a switching system.

To generate randomly-occurring disturbances, the switching system,
\begin{equation} \label{eq:wpk1} 
\gls{wpk} \sim 
\begin{cases*}
	0 & with probability $1-\gls{epsilon}$, \\
	\mathcal{N}\left( 0, \sigma_{w_p}^2 \right) & with probability \gls{epsilon},
\end{cases*}
\end{equation}
may be used, where \gls{wpk} is either 0 or is sampled from the normal distribution, \gls{Ndist}, with mean zero and variance \gls{sigmawp2}.  When the probability \gls{epsilon} is low ($\gls{epsilon}<<1$), this system produces infrequent shocks.

Alternatively, a mixture of two distributions may be used \citep{robertson_detection_1995}:
\begin{equation} \label{eq:wpk2}
\gls{wpk} \sim 
	\begin{cases*}
		\mathcal{N}\left(0, \sigma_{w_p}^2\right) & with probability $1-\gls{epsilon}$, \\
		\mathcal{N}\left(0, b^2\sigma_{w_p}^2\right) & with probability $\gls{epsilon}$.
	\end{cases*}
\end{equation}

In this formulation, \gls{sigmawp} represents the standard deviation of the noise in periods between random shocks and\gls{b} is typically large so that the magnitude of the shocks is many times greater than \gls{sigmawp}. One benefit of (\ref{eq:wpk2}) is that the distribution of \gls{wpk} is conditionally Gaussian, whereas in (\ref{eq:wpk1}) it has a non-smooth (i.e. degenerate) probability density function.

Figure \ref{fig:wpk-pdf} illustrates the probability density of \gls{wpk} in the case of (\ref{eq:wpk2}) with $\gls{sigmawp}=0.01$, $\gls{b}=100$, and $\gls{epsilon}=0.01$. Although it is difficult to discern from the plot, this is a mixture distribution with two components. The component that generates the infrequent shocks is barely visible because of its low probability. In this example, 99 percent of the probability lies within a narrow range (-0.036 < \gls{wpk} < 0.036). However, the shocks, which occur with probability 0.01, have much higher amplitude ($\gls{b}\gls{sigmawp}=1$).

\begin{figure}[ht]
	\centering
	\includegraphics[width=11.5cm]{wpk-pdf-4.pdf}
	\caption{Probability density of a random shock signal}
	\label{fig:wpk-pdf}
\end{figure}

When dealing with a system having more than one \gls{RODD}, where each random shock is independent, the notation is
\begin{equation} \label{eq:wpik2}
	w_{p,i}(k) \sim 
	\begin{cases*}
		\mathcal{N}\left(0, \sigma_{w_p,i}^2\right) & with probability $1-\epsilon_i$, \\
		\mathcal{N}\left(0, b_i^2\sigma_{w_p,i}^2\right) & with probability $\epsilon_i$.
	\end{cases*},
\end{equation}
where $i \in \left\{1, 2, ..., n_p\right\}$.

The choice of $A(q^{-1})$ and $B(q^{-1})$ in (\ref{eq:RODD}) determines the nature of the \gls{RODD}. For example, if $B(q^{-1})=1$ and $A(q^{-1})=1-q^{-1}$, $p(k)$ will be a random-walk process with infrequent, large step changes.

% Add symbol to glossary
Using \gls{nabla} to denote $1-q^{-1}$, the \gls{RODD} \textit{step-disturbance} process can be defined as
\begin{equation} \label{eq:RODD-step}
	\gls{pk} = \frac{1}{\gls{nabla}}\gls{wpk}.
\end{equation}

A \gls{RODD} \textit{ramp-disturbance}, consisting of a series of ramps with randomly-occurring changes in slope, may be generated using
\begin{equation} \label{eq:RODD-ramp}
	\gls{pk} = \frac{1}{\gls{nabla}^2}\gls{wpk}.
\end{equation}

A \gls{RODD} consisting of randomly-occurring decaying exponential changes may be generated using
\begin{equation} \label{eq:RODD-exp}
	\gls{pk} = \frac{1}{(1-a_1q^{-1})\gls{nabla}}\gls{wpk},
\end{equation}
where  $0<a_1<1$. Note that $a_1=0$ corresponds to the case of a \gls{RODD} step disturbance (\ref{eq:RODD-step}) and $a_1=1$ to that of a \gls{RODD} ramp disturbance (\ref{eq:RODD-ramp}). 

An equivalent state-space representation of (\ref{eq:RODD-exp}) is
\begin{equation} \label{eq:RODD-ss}
	\begin{split}
		\mathbf{x}_p(k+1) & =\left[\begin{array}{cc}
			1 & 1 \\
			0 & a_1
		\end{array}\right] \mathbf{x}_p(k) +\left[\begin{array}{cc}
			0 \\
			1
		\end{array}\right] w_p(k) \\
		p(k) & =\left[\begin{array}{cc}
			1 & 0
		\end{array}\right] \mathbf{x}_p(k),
	\end{split}
\end{equation}
where $\mathbf{x}_p(k) \in \mathbb{R}^2$ is the state vector.

A disturbance with a combination of different \gls{RODD} types is also possible.  For example, a state-space representation of a \gls{RODD} consisting of step changes and ramps is
\begin{equation} \label{eq:RODD-step-ramp}
	\begin{split}
		\mathbf{x}_p(k+1) & =\left[\begin{array}{cc}
			1 & 1 \\
			0 & 1
		\end{array}\right] \mathbf{x}_p(k) +\left[\begin{array}{cc}
			1 & 0 \\
			0 & 1
		\end{array}\right] \mathbf{w}_p(k) \\
		p(k) & =\left[\begin{array}{cc}
			1 & 0
		\end{array}\right] \mathbf{x}_p(k),
	\end{split}
\end{equation}

where $\mathbf{w}_p(k)$ is a vector of two independent random shock signals generated by (\ref{eq:wpik2}). Simulated examples of these \gls{RODD}s are presented in figures \ref{fig:rodd-sim-plots} and \ref{fig:rodd-sim-plot2}.

\subsection{Hidden Markov models} \label{sec:HMM}

\textit{Hidden Markov models} (\gls{HMM}) can be used to simulate a more diverse set of switching behaviours than those of the \gls{RODD} model described in the previous section \citep{wong_realistic_2009}. A Markov process or Markov chain is a stochastic model used to describe a sequence of discrete events for which the probability of future events depends only on the current state. A HMM is a Markov model with states that are not fully observable (i.e. hidden or observed with a measurement error).

To illustrate the basic concept, we can define the state of the random shock generating process (\ref{eq:wpk2}) as a Markov model state \gls{gammak} with two possible values:
\begin{equation} \label{eq:gamma-k}
	\gamma(k) = 
	\begin{cases*}
		0: & no shock, \\
		1: & shock.
	\end{cases*}
\end{equation}

% Add terms to Glossary
\glsadd{pagb} \glsadd{PrAgB}
$\gls{gammak}=0$ represents the system mode when no shock occurs and $\gls{gammak}=1$ represents the mode when a shock occurs. The switching of \gls{gammak} can then be defined by a \textit{transition matrix}, $\Pi$, which describes the probabilities of transitioning from the mode at time $k$ to the mode at time $k+1$:
\begin{equation} \label{eq:Pi}
	\begin{aligned}
	\Pi &= \left(\pi_{ij} \forall i,j\in \{1,2,...,n_j\}\right) \\
	\pi_{ij} &= \Pr\left( \gamma(k)=j-1 \mid \gamma(k-1)=i-1 \right),
	\end{aligned}
\end{equation}
where \gls{nj} is the number of possible system modes---which is 2 in this case of the random shock---and $\pi_{ij}$ is the probability that the shock mode at time $k$ is $j-1$ given that it was $i-1$ at time $k-1$.

For example, the Markov process equivalent to the random shock used in the \gls{RODD} model (\ref{eq:wpk2}) would have the transition probability matrix
\begin{equation} \label{eq:Pi-RODD-step}
	\glsadd{Piwp}\Pi_{w_{p}} = \begin{bmatrix}
	1-\epsilon & \epsilon \\
	1-\epsilon & \epsilon
	\end{bmatrix}
\end{equation}
is used. In this case, since $w_{p}(k)$ is an independent random variable, it does not depend on the previous state. Therefore, the rows of \gls{Piwp} are identical.

The use of the Markov model thus allows transition probabilities that depend on the current state. For example, consider a disturbance where the signal switches infrequently between samples from two or more distributions with different parameters. The probabilities of switching from one distribution to another may be different. Such a disturbance process could be simulated with a hidden Markov model by conditioning the distribution from which \gls{wpk} is sampled on a Markov state \gls{rk} with an arbitrary number of modes:
\begin{equation} \label{eq:mog-example}
	\begin{split}
		w_p(k) \sim 
		\begin{cases*}
			\mathcal{N}\left(\mu_{w_p,1}, \sigma_{w_p,1}\right) & if $r(k)=1$, \\
			\mathcal{N}\left(\mu_{w_p,2}, \sigma_{w_p,2}\right) & if $r(k)=2$, \\
			... & ...\\
			\mathcal{N}\left(\mu_{w_p,n_j}, \sigma_{w_p,n_j}\right) & if $r(k)=n_j$.
		\end{cases*} \\
	\Pr(r(k)=j-1 \mid r(k-1)=i-1)=\pi_{ij} \forall i,j \in {1,2,...,n_j}
	\end{split}
\end{equation}

To make the notation more concise, allow the value of any time-varying discrete variable such as $\sigma_{w_p} \in \left\{\sigma_{w_p,1}, \sigma_{w_p,2},..., \sigma_{w_p,n_j}\right\}$, to be determined by the value of the Markov state $r(k)$. Thus,
\begin{equation} \label{eq:A-selection}
	\sigma_{w_p}(r(k)) = 
	\begin{cases*}
		\sigma_{w_p,1} & if $r(k)=1$, \\
		\sigma_{w_p,2} & if $r(k)=2$, \\
		... & ...\\
		\sigma_{w_p,n_j} & if $r(k)=n_j$.
	\end{cases*}
\end{equation}

With this notation, (\ref{eq:mog-example}) can be written more concisely as
\begin{equation} \label{eq:mog-example2}
	\begin{aligned}
		w_p(k) &\sim \mathcal{N}\left(\mu_{w_p}(r(k)), \sigma_{w_p}(r(k))\right) \\
		\Pr(r(k) &= j-1 \mid r(k-1)=i-1)=\pi_{ij} \forall i,j \in {1,2,...,n_j}.
	\end{aligned}
\end{equation}
where $\mu_{w_p}\in\left\{\mu_{w_p,1},\mu_{w_p,2},...,\mu_{w_p,n_j}\right\}$. This model is known as a \textit{mixture of Gaussians} and can be considered a special-case of a HMM-based disturbance model \citep{wong_disturbance_2007}.

The general \gls{HMM} disturbance process is described by the following \textit{Markov jump linear system} (\gls{MJLS}) \citep{costa_discrete-time_2005}. A state-space representation with time-varying system matrices $\mathbf{A}(\gamma(k))$, $\mathbf{B}(\gamma(k))$, and $\mathbf{C}(\gamma(k))$ can then be defined
\begin{equation} \label{eq:MJLS}
	\begin{aligned}
	\mathbf{x}_p(k+1) &= \mathbf{A}(r(k)) \mathbf{x}_p(k) + \mathbf{B}(r(k))\mathbf{w}_p(k) \\
	\mathbf{p}(k) &= \mathbf{C}(r(k)) \mathbf{x}_p(k) + \mathbf{e}_p(k)
	\end{aligned}
\end{equation}

As well as $\mathbf{w}_p(k)$, $\mathbf{e}_p(k)$ may also be a switching random variable. (\ref{eq:MJLS}) is a versatile model suitable for representing and simulating a diverse family of stochastic disturbances.

\subsection{Bounded disturbances} \label{sec:bounded}

The \textit{bounded random walk} (\gls{BRW}) is a stochastic process proposed by \cite{nicolau_stationary_2002}. The discrete-time version has the difference equation
\begin{equation} \label{eq:brw}
		p(k+1) = p(k) + a(p(k)) + e(k),
\end{equation}
where $e(k)$ is a random noise with variance $\sigma_e^2$, and $a(\cdot)$ is a function defined as
\begin{equation}
	a(x) = e^{\beta}\left(e^{-\alpha_{1}\left(x - \tau\right)} - e^{\alpha_{2}\left(x - \tau\right)}\right),
\end{equation}
where $\beta$, $\alpha_{1}$, and $\alpha_{2}$ are constants.  From (\ref{eq:brw}) it can be deduced that
\begin{equation}
	\mathbb{E}\{p(k+1)|p(k)\} = p(k) + a(p(k)).
\end{equation}

Therefore, $a(p(k))$ has the effect of an additive bias or time-varying adjustment to $p(k+1)$ that depends on $p(k)$. The shape of $a(\cdot)$ is determined by the constants $\alpha_{1}$,  $\alpha_{2}$, $\beta$, and $\tau$. Figure \ref{fig:brw-a} shows $a(p(k))$ in the case where $\tau=100$, $\beta=-15$, and $\alpha_{1}=\alpha_{2}=3$.  From this, it is clear that in the vicinity of $p(k)=\tau$, $a(p(k))\approx0$. When $a(p(k))=0$, (\ref{eq:brw}) is the equation for a random walk. However, outside a neighbourhood of $p(k)=\tau$, $a(p(k))$ increases for low $p(k)$ or decreases for high $p(k)$. This has the effect of causing $p(k+1)$ to revert towards the mean ($\tau$) whenever $p(k)$ strays outside the neighbourhood. 

\begin{figure}[ht]
	\centering
	\includegraphics[height=5cm]{images/brw_a.pdf}
	\caption{A bounded random walk bias function}
	\label{fig:brw-a}
\end{figure}

Figure \ref{fig:brw-sim} shows a simulation of a bounded random walk with the parameter values as above, and for comparison, an unbounded random walk (labelled `RW') generated with the same noise input. The dashed lines at $p(k)=95$ and $p(k)=105$ roughly indicate the location of the lower and upper bounds which the BRW only marginally exceeds.

\begin{figure}[ht]
	\centering
	\includegraphics[height=5cm]{images/brw_sim.pdf}
	\caption{Examples of a bounded and unbounded random walk}
	\label{fig:brw-sim}
\end{figure}

Unlike a simple random walk, the \gls{BRW} is stationary. \cite{nicolau_stationary_2002} derived a formula for the form of the unconditional (i.e. stationary) probability distribution of the continuous-time \gls{BRW}. Figure \ref{fig:brw-pdf} shows the normalized stationary probability density of the same \gls{BRW} as above. For comparison, the probability density of a random walk process after 20 sample periods is also shown. It can be seen that there is a significant probability that the random walk would exceed the bounds of this \gls{BRW} after 20 sample periods. It can also be seen that the central part of the probability distribution of the \gls{BRW} is flat, indicating that all values within the bounds are equally likely after a large number of samples, similar to a uniform probability distribution.

%\begin{equation}
%	p_{BRW}(x) \propto \sigma^{-2} \exp \left\{-\frac{2 e^{k}}{\sigma^{2}}\left(\frac{e^{-\alpha_{1}(x-\tau)}}{\alpha_{1}}+\frac{e^{\alpha_{2}(x-\tau)}}{\alpha_{2}}\right)\right\}
%\end{equation}

\begin{figure}[ht]
	\centering
	\includegraphics[height=5cm]{images/brw_pdf.pdf}
	\caption{Probability distributions of bounded and unbounded random walks}
	\label{fig:brw-pdf}
\end{figure}

However, the \gls{BRW} as described by (\ref{eq:brw}) is not guaranteed to be stable. Extreme values of $p(k)$ may cause $|a(p(k))|$ to be greater than $2|p(k)|$, which results in rapid divergence. This would cause computational errors in a numerical simulation. To avoid this, \cite{nicolau_stationary_2002} recommends adding a conditional regularizing step which forces reversion towards the mean, $\tau$, when the correction bias is too large. Instead of (\ref{eq:brw}), a conditional difference equation,
\begin{equation} \label{eq:brw-reg}
	p(k+1) = \begin{cases*}
		p(k) + a(p(k)) + e(k) & if $\left|a(p(k)) \right| < 2\left| p(k) - \tau \right|$, \\
		\tau + \phi(p(k) - \tau) + e(k) & if $\left|a(p(k)) \right| \geq 2\left| p(k) - \tau \right|$,
	\end{cases*}
\end{equation}
is used, where $\phi$ is a constant such that $0<\phi<1$. The size of $\phi$ determines how fast $p(k)$ reverts to $\tau$, the stationary mean of the \gls{BRW}, when it is outside the stable region.

Since the \gls{BRW} has a non-Gaussian probability distribution, analysis of the properties of any dynamical system with a \gls{BRW} is difficult. However, for simulation purposes, the \gls{BRW} is a simple and practical solution to the problem of bounding a random variable.

The \gls{BRW} concept can be extended to \gls{RODD}s. A \gls{RODD} step disturbance (\ref{eq:RODD-step}) is a random walk with a switching noise variance (\ref{eq:wpk2}). The concern when trying to bound such a disturbance is the large step changes that occur infrequently. Since the probability of the shock, as well as the sign and amplitude of the step, are independent random variables, a \gls{RODD} step disturbance that happens to be at one of the bounds is as likely to step outside the bound as it is to step back inside the bounded region. The conditional regularity used in the \gls{BRW} (\ref{eq:brw-reg}) would prevent any computational problems. 

%However, this may not be an ideal way to generate a bounded RODD... 
% \textbf{TODO: Add alternative bounded RODD model if I ended up needing it.}


\section{State estimation} \label{sec:estimation}

State estimation is the task of estimating the values of the state variables of a dynamic model of a system given a set of measurements from the system. In process control applications, state estimates are required online (i.e. in real time), in order to provide the best possible estimate of the states at the current time (or a prediction of their values at the next time instant) in order to calculate an appropriate control action.

Consider the diagram of an input-output system model in Figure \ref{fig:model_diag_uwvy}. Here, \gls{uk} $\in \mathbb{R}^{n_u}$ is a vector of known input variables at time instant $k$, \gls{wk} $\in \mathbb{R}^n$ is a vector of unmeasured state disturbances, $\mathbf{v}(k) \in \mathbb{R}^{n_y}$ is a vector of output disturbances or measurement errors, and \gls{yk} $\in \mathbb{R}^{n_y}$ is the vector of output variables. The box represents a mathematical model that relates the inputs to the outputs and may be time-varying. 
\begin{figure}[ht]
	\centering \glsadd{uk}\glsadd{yk}\glsadd{wk}\glsadd{vk}
	\includegraphics[width=8cm]{images/model_diag_uwvy.pdf}
	\caption{System model diagram}
	\label{fig:model_diag_uwvy}
\end{figure}

A convenient form in which to represent discrete-time, linear, possibly time-varying, dynamical system models for state estimation and control purposes, is the state-space representation
\begin{equation} \label{eq:ss_rep_uwy}
	\begin{aligned} \glsadd{xk} \glsadd{A} \glsadd{B} \glsadd{C}
		\mathbf{x}(k+1) &= \mathbf{A}(k) \mathbf{x}(k) + \mathbf{B}(k) \mathbf{u}(k) + \mathbf{w}(k), \\
		\mathbf{y}(k) &= \mathbf{C}(k) \mathbf{x}(k) + \mathbf{v}(k).
	\end{aligned}
\end{equation}
where \gls{xk} $\in \mathbb{R}^n$ is a vector of state variables, \gls{A}$\in \mathbb{R}^{n \times n}$ is the state transition matrix at time $k$, $\mathbf{B}(k) \in \mathbb{R}^{n \times n_u}$ is the input matrix at time $k$, $\mathbf{C}(k) \in \mathbb{R}^{n_y \times n}$ is the output matrix at time $k$. In this work, the system matrices are not time-varying and are therefore denoted $\mathbf{A}$, $\mathbf{B}$, and $\mathbf{C}$ in the remainder of this chapter.

The \textit{Kalman filter} \citep{kalman_new_1960} is the optimal estimator for a linear system in which the unmeasured disturbances and measurement errors are Gaussian random variables with mean values of zero. There are two commonly-used implementations of the Kalman filter, the \textit{prediction form} and the \textit{filtering form}. In the prediction form, the estimates of the states at the next time instant ($k+1$), given the information available at the current time ($k$) are calculated using
\begin{equation} \glsadd{yMk}
\begin{aligned} \label{eq:xkp1_hat_p}
	\glsadd{xkp1_pred}\mathbf{\hat{x}}(k+1 \mid k) &= \mathbf{\hat{x}}(k+1 \mid k-1) + \mathbf{K}_p(k) \big( \mathbf{y}_M(k) - \mathbf{\hat{y}}(k \mid k-1) \big) \\
	&= \mathbf{A}\mathbf{\hat{x}}(k \mid k-1) + \mathbf{B}u(k) + \mathbf{K}_p(k) \big( \mathbf{y}_M(k) - \mathbf{C} \mathbf{\hat{x}}(k \mid k-1) \big)
\end{aligned}
\end{equation}
where \gls{xk_pred} is the prediction of the states at time $k$ that was made with the information available at the previous time ($k-1$), \gls{yMk} is the current measurement of the output, and \gls{Kpk} $\in \mathbb{R}^{n \times n_y}$ is a (possibly time-varying) correction gain.

In the filtering form, which is used in this work, the estimated states and outputs at the current time are calculated given the information available at the current time using
\begin{equation} \label{eq:xkyk_hat}
	\begin{aligned}
		\glsadd{xk_pred}\mathbf{\hat{y}}(k \mid k-1) &= \mathbf{C} \mathbf{\hat{x}}(k \mid k-1) \\
		\glsadd{xk_hat}\mathbf{\hat{x}}(k \mid k) &= \mathbf{\hat{x}}(k \mid k-1) + \mathbf{K}(k) \big( \mathbf{y}_M(k) - \mathbf{\hat{y}}(k \mid k-1)  \big) \\
		\glsadd{yk_hat}\mathbf{\hat{y}}(k \mid k) &= \mathbf{C} \mathbf{\hat{x}}(k \mid k)
	\end{aligned}
\end{equation}
where \gls{Kk} $\in \mathbb{R}^{n \times n_y}$ is a (possibly time-varying) correction gain. The predictions of the states at the next time instant are calculated using
\begin{equation} \label{eq:xkp1_hat}
	\glsadd{xk_pred}\mathbf{\hat{x}}(k+1 \mid k) = \mathbf{A} \mathbf{\hat{x}}(k \mid k) + \mathbf{B} \mathbf{u}(k).
\end{equation}

An intuitive interpretation of the Kalman filter is that it takes the predictions of the states at time $k$ made in the previous time instant using the system model, and corrects them based on the difference between the current output measurement, \gls{yMk}, and the output predicted by the model, $\mathbf{C} \mathbf{\hat{x}}(k \mid k-1)$. The correction step (\ref{eq:xkyk_hat}) and prediction step (\ref{eq:xkp1_hat}) are executed iteratively each time step, given a prior prediction of the states at time zero, $\mathbf{\hat{x}}(0 \mid -1)=\mathbf{\hat{x}}_0$.

Although the predicted states, \gls{xk_pred}, are identical in both cases, the use of the updated (i.e. \textit{a posteriori}) estimates, \gls{xk_hat}, in the filtering form instead of the predicted states leads to an optimal estimate taking account of all the information available.

To track a system with time-varying parameters, a dynamic estimator is needed with a time-varying correction gain. In the case of the filtering form of the Kalman filter, \gls{Kk} is calculated at each time instant using
\begin{equation} \label{eq:Kk}
	\glsadd{Kk}\mathbf{K}(k) = \mathbf{P}(k \mid k-1)\mathbf{C}^\intercal \mathbf{S}^{-1}(k),
\end{equation}
where \gls{Sk}, which is given by
\begin{equation} \label{eq:Sk}
	\gls{Sk} = \mathbf{C}\mathbf{P}(k \mid k-1)\mathbf{C}^\intercal + \gls{R},
\end{equation}
is the output prediction error covariance matrix and \gls{Pk_pred} is the state estimation error covariance matrix calculated in the previous time instant. \gls{R}, which is also time invariant in this work, is the covariance matrix of the measurement noises,
\begin{equation} \label{eq:R} \glsadd{E}
	 \gls{R} = \mathbb{E}\{ \mathbf{v}(k) \mathbf{v}^\intercal(k) \},
\end{equation}
where \gls{E} is the expectation operator.

The corrected error covariance may be calculated using
\begin{equation} \label{eq:Pk}
	\mathbf{P}(k \mid k) = \left( \mathbf{I}_n - \mathbf{K}(k) \mathbf{C} \right) \mathbf{P}(k \mid k-1),
\end{equation}
given an initial covariance estimate at time zero, $\mathbf{P}(0 \mid -1)=\mathbf{P}_0$. However, to reduce numerical errors due to rounding, the computation of $\mathbf{P}(k \mid k)$ is carried out in this work using the Joseph stabilized version of (\ref{eq:Pk})
 \begin{equation} \label{eq:Pk-stab}
 	\mathbf{P}(k \mid k) = \left( \mathbf{I}_n - \mathbf{K}(k) \mathbf{C} \right ) \mathbf{P}(k \mid k-1) \left( \mathbf{I}_n - \mathbf{K}(k) \mathbf{C} \right )^\intercal + \mathbf{K}(k)  \mathbf{R} \mathbf{K}(k)^\intercal,
 \end{equation}
where \gls{identity} is the identity matrix (see \cite{lewis_optimal_2008} for example).

The prediction of the error covariance in the next time step is made using
\begin{equation} \label{eq:Pkp1} \glsadd{Pkp1_pred}
	\mathbf{P}(k+1 \mid k) = \mathbf{A} \mathbf{P}(k \mid k)  \mathbf{A}^\intercal  + \gls{Qk},
\end{equation}
where \gls{Qk} is the time-varying covariance of the process disturbances,
\begin{equation} \label{eq:Q}
	\gls{Qk} = \mathbb{E}\{ \mathbf{w}(k) \mathbf{w}^\intercal(k) \}.
\end{equation}

Algorithm \ref{alg:kf} defines the sequence of the Kalman filter calculations during each time step. 
\begin{algorithm}
	\caption{Kalman filter update}\label{alg:kf}
	%\algorithmfootnote{$y_0$ denotes the initial value.}
	\begin{algorithmic}
		\Require $\mathbf{A},\mathbf{B},\mathbf{C},\mathbf{\hat{x}}(k \mid k-1), \mathbf{P}(k \mid k-1), \gls{Qset}, \gls{R}, \mathbf{\gamma}(k), \mathbf{u}(k), \mathbf{y}_M(k)$
		\State calculate $\mathbf{S}(k)$ (\ref{eq:Sk})
		\State calculate $\mathbf{K}(k)$ (\ref{eq:Kk})
		\State calculate $\mathbf{\hat{x}}(k \mid k)$ and $\mathbf{\hat{y}}(k \mid k)$ (\ref{eq:xkyk_hat})
		\State calculate $\mathbf{P}(k \mid k)$ (\ref{eq:Pk-stab})
		\State calculate $\mathbf{\hat{x}}(k+1 \mid k)$ (\ref{eq:xkp1_hat})
		\State $\gls{Qk} \gets \gls{Qset}(\gamma(k))$
		\State calculate $\mathbf{P}(k+1 \mid k)$ (\ref{eq:Pkp1})
	\end{algorithmic}
\end{algorithm}
Note that in a control application, the manipulated input \gls{uk} must be computed by the control algorithm. This may be done before the Kalman filter calculations in algorithm \ref{alg:kf} if the prior prediction of the states in the current time instant, \gls{xk_pred}, is used by the control algorithm. Alternatively, slightly better control performance might be achieved if the control algorithm uses the updated (a-posteriori) state estimates, \gls{xk_hat}, instead. In the latter case, the Kalman filter calculations must be interrupted to compute the control action after the state correction step (\ref{eq:xkyk_hat}) and prior to the prediction step (\ref{eq:xkp1_hat}), when \gls{uk} is needed.

\begin{figure}[ht]
	\centering
	\includegraphics[width=8cm]{images/model_diag_upwvy.pdf}
	\caption{System model with disturbance inputs and manipulated inputs}
	\label{fig:model_diag_upwvy}
\end{figure}
In the case where the system has additional disturbance inputs, $\mathbf{p}(k) \in \mathbb{R}^{n_p}$, as depicted in Figure \ref{fig:model_diag_upwvy}, the state-space equations (\ref{eq:ss_rep_uwy}) are modified to include these and the input matrix is split into two, $\mathbf{B}_u \in \mathbb{R}^{n \times n_u}$ and $\mathbf{B}_p \in \mathbb{R}^{n \times n_p}$,
\begin{equation} \label{eq:ss_rep_upwy}
	\begin{aligned}
		\mathbf{x}(k+1) = \mathbf{A} \mathbf{x}(k) + \mathbf{B}_u \mathbf{u}(k) + \mathbf{B}_p \mathbf{p}(k) + \mathbf{w}(k), \\
		\mathbf{y}(k) = \mathbf{C} \mathbf{x}(k) + \mathbf{v}(k).
	\end{aligned}
\end{equation}

For state estimation in the presence of disturbances, which is always the case in practice, a suitable model of the disturbances is needed. This model is shown in Figure \ref{fig:model_diag_wpupwvy} with an additional set of random variables \gls{wpkv} at its input.
\begin{figure}[ht]
	\centering
	\includegraphics[width=12.5cm]{images/model_diag_wpupwvy.pdf}
	\caption{System with process model and disturbance model}
	\label{fig:model_diag_wpupwvy}
\end{figure}

A state-space representation of the combined system including the disturbance model can be constructed. This will be referred to as the \textit{augmented model},
\begin{equation} \label{eq:ss_rep_xa} \glsadd{xak} \glsadd{Aa} \glsadd{Ba} \glsadd{Ca}
	\begin{aligned}
		\mathbf{x}_a(k+1) = \mathbf{A}_a \mathbf{x}_a(k) + \mathbf{B}_{a,u} \mathbf{u}(k) + \mathbf{B}_{a,w} \mathbf{w}_{a}(k), \\
		\mathbf{y}(k) = \mathbf{C}_a \mathbf{x}_a(k) + \mathbf{v}(k),
	\end{aligned}
\end{equation}
where \gls{xak} $\in \mathbb{R}^{n+n_p}$ is an augmented state vector that includes the states of both the process model and the disturbance model, and $\mathbf{w}_a(k) \in \mathbb{R}^{n+n_p}$ is an augmented vector of random variables combining $\mathbf{w}(k)$ and $\mathbf{w}_p(k)$. However, this notation with subscript `a' is only used in this chapter. In subsequent chapters, the subscript is dropped for simplicity since all references to the model state vector and model state estimates relate to the augmented model used in state estimation.

Although the random shock in a \gls{RODD} is unmeasured, it may be observable from the measurements of the outputs of the system. However, as mentioned in Section \ref{chap-lit-review}, systems with \gls{RODD}s pose problems for state estimation using standard Kalman filters due to the switching of the noise model parameters, namely, the variance of $w_p(k)$ (\ref{eq:wpk2}). As explained by \cite{andersson_adaptive_1985}, a trade-off must be made during the filter design between its ability to respond to the infrequent disturbance when it occurs, and its sensitivity to noise at other times.


\subsection{Multiple model approaches} \label{sec:multi-model}

One option for state estimation of switching (i.e. hybrid) systems is the so-called \textit{multiple-model approach}. Multi-model observers account for different possible hypotheses about the current and past states of the system and infer from these an overall `best' estimate of the current states. To achieve this, an independent Kalman filter is maintained for each hypothesis and a weighted average of the estimates by each filter is calculated using the conditional probabilities of each hypothesis given current and past measurements.

Let the number of hypotheses and Kalman filters be \gls{nh} and the \textit{shock occurrence hypothesis} associated with Kalman filter $f$ at time $k$ be
\begin{equation} \label{eq:gammak} \glsadd{gamma_fk}
	\gamma_{f}(k) \in \left\{0, 1 \right\} \forall{k \ge 0}.
\end{equation}

First, consider the case of estimating only one shock signal (\ref{eq:wpk2}). Therefore, \gls{gamma_fk} is a scalar. The transition probabilities of the random shock are independent of previous shocks:
\begin{equation} \label{eq:Pr_gammak_given_gammakm1}
	\begin{aligned}
		& \Pr\left(\gamma_{f}(k)=0 \mid \gamma_{f}(k-1)\right) = \Pr\left(\gamma_{f}(k)=0\right) = 1-\epsilon, \\
		& \Pr\left(\gamma_{f}(k)=1 \mid \gamma_{f}(k-1)\right) = \Pr\left(\gamma_{f}(k)=1\right) = \epsilon.
	\end{aligned}
\end{equation}

After $k$ time steps, the complete shock occurrence hypothesis associated with filter $f$ is
\begin{equation} \label{eq:Gammak} \glsadd{Gammafk}
	\Gamma_f(k) = \left\{ \gamma_f(0), \gamma_f(1), ..., \gamma_f(k) \right\}.
\end{equation}

The known system inputs and output measurements up to time $k$ are
\begin{equation} \label{eq:Uk_Yk}
	\begin{aligned}
		\mathbf{U}(k) = \left\{ \mathbf{u}(0), \mathbf{u}(1), ..., \mathbf{u}(k) \right\} \\
		\mathbf{Y}_M(k) = \left\{ \mathbf{y}_M(0), \mathbf{y}_M(1), ..., \mathbf{y}_M(k) \right\}.
	\end{aligned}
\end{equation}

Assume that new measurements are made available at each time instant. The probability of the shock hypothesis sequence associated with filter $f$ given the data up to time $k-1$ can be calculated recursively using
\begin{multline} \label{eq:Pr_Gammak_given_Ykm1}
	\Pr(\Gamma_f(k) \mid \mathbf{Y}_M(k-1)) = 
	\Pr(\gamma_f(k) \mid \gamma_f(k-1)) \Pr(\Gamma_f(k-1) \mid \mathbf{Y}_M(k-1)).
\end{multline}

The conditional probability densities of the measurements \gls{yMk} are approximated by Gaussian distributions centred on the output predictions and with the covariance of the output prediction error, \gls{Sfk},
% \mathbf{C} 
\begin{equation} \label{eq:p_yk_given_Gammak_Ykm1}
	p(\mathbf{y}_M(k) \mid \Gamma_f(k), \mathbf{Y}_M(k-1)) \approx \mathcal{N}\left(\mathbf{y}_M(k), \mathbf{\hat{y}}_{f}(k \mid k-1),	\mathbf{S}_f(k) \right)
\end{equation}
where $p(\cdot)$ here represents a probability density function, $\mathbf{\hat{x}}_{f}(k \mid k-1)$ and $\mathbf{P}_f(k \mid k-1)$ are the state predictions and prediction error covariances of each Kalman filter calculated in the previous time step, and \gls{Ndist2} is the multivariate normal probability density of $\mathbf{y}$ with mean $\mathbf{\mu}$ and variance $\Sigma$. As before, $\mathbf{\hat{y}}_{f}(k \mid k-1)$ and $\mathbf{S}_f(k) $ are given by 
\begin{equation} \label{eq:yfk_pred}
	\mathbf{\hat{y}}_{f}(k \mid k-1) = \mathbf{C}\mathbf{\hat{x}}_{f}(k \mid k-1)
\end{equation}
and
\begin{equation} \label{eq:Sfk}
	\gls{Sfk} = \mathbf{C}\mathbf{P}_f(k \mid k-1)\mathbf{C}^\intercal + \gls{R}.
\end{equation}

The estimate of the probability of the shock sequence $\Gamma_f(k)$ given the data up to time $k$ is
\begin{equation} \label{eq:Pr_Gammak_given_Yk}
	\Pr(\Gamma_f(k) \mid \mathbf{Y}_M(k)) = \frac{q_f(k)}{\sum_{f=1}^{n_h} q_f(k)},
\end{equation}
where
\begin{equation} \label{eq:qfk}
	q_f(k) = p(\mathbf{y}_M(k) \mid \Gamma_f(k), \mathbf{Y}_M(k-1)) \Pr(\Gamma_f(k) \mid \mathbf{Y}_M(k-1)).
\end{equation}

The Kalman filters for tracking each hypothesis use the state-space representation of the augmented system model (\ref{eq:ss_rep_xa}). 
However, in the case of a system with a \gls{RODD}, the disturbance inputs include the non-Gaussian random variable, $\mathbf{w}_p(k)$, as well as the usual Gaussian disturbances on the rest of the states, $\mathbf{w}(k)$,
\begin{equation} \label{eq:wak}
	\mathbf{w}_a(k) = \begin{bmatrix}
		\mathbf{w}(k) \\
		\mathbf{w}_p(k)
	\end{bmatrix}.
\end{equation}

The system is therefore a \textit{hybrid dynamical system} because it has a switching noise covariance matrix. Define the set of possible covariance matrices as
\begin{equation} \label{eq:init_Q_R}
	\gls{Qset} = \left\{\mathbf{Q}_0, \mathbf{Q}_1\right\},
\end{equation}
and, for convenient notation, let $\mathcal{Q}$ be indexed by the shock indicator variable $\gamma_f(k)$,
\begin{equation} \label{eq:init_Q}
	\gls{Qset}(\gamma_f(k)) = 
	\begin{cases*}
		\mathbf{Q}_0 & \text{if} $\gamma_f(k)=0$, \\
		\mathbf{Q}_1 & \text{if} $\gamma_f(k)=1$.
	\end{cases*}
\end{equation}

% TODO: add positive definite and symmetric numerical fix.
At the start of simulation, $f$ Kalman filters are initialized with initial state estimates, $\mathbf{\hat{x}}_f(0) = \mathbf{\hat{x}}_{f,0}$, and initial error covariance estimates $	\mathbf{P}_f(0) = \mathbf{P}_{f,0}$. At each time instant, starting at $k=0$, the correction gains are calculated as in the previous section (\ref{eq:Sk}),
\begin{equation} \label{eq:Kfk}
	\mathbf{K}_f(k) = \mathbf{P}_f(k \mid k-1)\mathbf{C}^\intercal \mathbf{S}_f^{-1}(k).
\end{equation}

The corrected state and output estimates are calculated as in (\ref{eq:xkyk_hat}), given the current measurement using
\begin{equation} \label{eq:xfkyfk_hat}
	\begin{aligned}
		\mathbf{\hat{x}}_f(k \mid k) &= \mathbf{\hat{x}}_f(k \mid k-1) + \mathbf{K}_f(k) \big( \mathbf{y}_M(k) - \mathbf{C} \mathbf{\hat{x}}_f(k \mid k-1) \big) \\
		\mathbf{\hat{y}}_f(k \mid k) &= \mathbf{C} \mathbf{\hat{x}}_f(k \mid k).
	\end{aligned}
\end{equation}

The corrected error covariances are calculated as in (\ref{eq:Pk-stab}) using 
\begin{equation} \label{eq:Pkf-stab} \glsadd{Pfk}
	\mathbf{P}_f(k \mid k) = \left( \mathbf{I}_n - \mathbf{K}_f(k) \mathbf{C} \right ) \mathbf{P}_f(k \mid k-1) \left( \mathbf{I}_n - \mathbf{K}_f(k) \mathbf{C} \right )^\intercal + \mathbf{K}_f(k)  \gls{R} \mathbf{K}_f(k)^\intercal.
\end{equation}

An additional precaution is necessary here for numerical stability. $\mathbf{P}_f(k \mid k)$ should always be positive definite. However, because finite floating-point representations are inexact, it may potentially loose its positive definiteness. If this occurs, then \gls{Sfk} will also not be positive definite, and a numerical error is likely when calculating the probability density of the output estimates (\ref{eq:p_yk_given_Gammak_Ykm1}). To avoid this problem the following operation is carried out after (\ref{eq:Pkf-stab})
\begin{equation} \label{eq:Pkf-psd-fix}
	\mathbf{P}_f(k \mid k) = \frac{ \mathbf{P}_f(k \mid k) + \mathbf{P}_f(k \mid k)^\intercal )}{2}. 
\end{equation}
This ensures that $\mathbf{P}_f(k \mid k)$ is always positive definite.

The predicted states at the next time instant are calculated as in (\ref{eq:xkp1_hat})
\begin{equation} \label{eq:xfkp1_hat}
	\mathbf{\hat{x}}_f(k+1 \mid k) = \mathbf{A} \mathbf{\hat{x}}_f(k \mid k) + \mathbf{B} \mathbf{u}(k)
\end{equation}
and the predicted error covariances at the next time instant are calculated as in (\ref{eq:Pkp1}) using
\begin{equation} \label{eq:Pfkp1} \glsadd{Pfkp1_pred}
	\mathbf{P}_f(k+1 \mid k) = \mathbf{A} \mathbf{P}_f(k \mid k)  \mathbf{A}^\intercal  + \gls{Qset}(\gamma_f(k)).
\end{equation}

Note the difference between (\ref{eq:Pfkp1}) and (\ref{eq:Pkp1}).  Here, $\mathbf{P}_f(k+1 \mid k)$ is dependent on $\gamma_f(k)$, which determines the noise covariance matrix used in the update, whereas in (\ref{eq:Pkp1}), $\mathbf{Q}$ is time invariant.

Finally, the merged estimates of the states and outputs at the current time are the sum of the Kalman filter estimates weighted by the conditional probabilities from (\ref{eq:Pr_Gammak_given_Yk}),
\begin{equation} \label{eq:xkyk_hat_MKF}
	\begin{aligned}
		\mathbf{\hat{x}}(k \mid k) = \sum_{f=1}^{n_h} \mathbf{\hat{x}}_f(k \mid k) \Pr(\Gamma_f(k) \mid \mathbf{Y}_M(k)) \\
		\mathbf{\hat{y}}(k \mid k) = \sum_{f=1}^{n_h} \mathbf{\hat{y}}_f(k \mid k) \Pr(\Gamma_f(k) \mid \mathbf{Y}_M(k)).
	\end{aligned}
\end{equation}

A merged estimate of the covariance of the estimation errors is obtained using
\begin{equation} \label{eq:Pk_MKF}
	\begin{aligned}
	\mathbf{P}(k \mid k) = \sum_{f=1}^{n_h} \Pr(\Gamma_f(k) \mid \mathbf{Y}_M(k)) \left( \mathbf{P}_f(k \mid k) + \delta_\mathbf{\hat{x}}(k) \delta_\mathbf{\hat{x}}^\intercal(k) \right), \\
	\delta_\mathbf{\hat{x}}(k) = \mathbf{\hat{x}}(k \mid k) - \mathbf{\hat{x}}_f(k \mid k).
	\end{aligned}
\end{equation}

Algorithm \ref{alg:afmm} shows the sequence of operations and flow control loops to execute these computations during a simulation of length $N$ time steps.

\begin{algorithm}
	\caption{Multiple model observer simulation}  \label{alg:afmm}
	%\algorithmfootnote{$y_0$ denotes the initial value.}
	\begin{algorithmic}
			\Require $\mathbf{A}, \mathbf{B}, \mathbf{C}, \mathbf{\hat{x}}_0, \mathbf{\gamma}_{\text{init}}, \mathbf{p}_{\text{init}}, \mathbf{P}_0, \gls{Qset}, \gls{R}, \Pi, \mathbf{U}(N), \mathbf{Y}_M(N)$
			\For{$f \gets 1, n_h$}  \Comment{Initialize Kalman filters}  % \footnotemark
				\State $\mathbf{\hat{x}}_f(0 \mid -1) \gets \mathbf{\hat{x}}_0$
				\State $\mathbf{P}_f(0 \mid -1) \gets \mathbf{P}_0$
				\State $\mathbf{\gamma}_f(-1) \gets \mathbf{\gamma}_{\text{init},f}$
				\State $\Pr(\Gamma_f(-1)|\mathbf{Y}_M(-1))) \gets p_{\text{init},f}$
			\EndFor
			\For{$k \gets 0, N$}
			\For{$f \gets 1, n_h$}
				\State calculate $\mathbf{\hat{y}}_f(k \mid k-1)$ (\ref{eq:yfk_pred}) \Comment{KF output predictions}
				\State calculate $\mathbf{S}_f(k \mid k-1)$ (\ref{eq:Sfk})
			\EndFor
			\State $\mathbf{y}_M(k) \gets \mathbf{Y}_M(k)$ \Comment{Acquire measurements}  % \footnotemark
			\State $\mathbf{u}(k) \gets \mathbf{U}(k)$
			\For{$f \gets 1, n_h$}
				\State calculate $\Pr(\Gamma_f(k) \mid \mathbf{Y}_M(k))$ (\ref{eq:Pr_Gammak_given_Ykm1}, \ref{eq:p_yk_given_Gammak_Ykm1}, \ref{eq:Pr_Gammak_given_Yk}, \ref{eq:qfk})     \Comment{Probability update}  % \footnotemark
			\EndFor
			\State $\Gamma_f(k \mid k), \mathbf{\hat{x}}_f(k \mid k), \mathbf{P}_f(k \mid k) \gets ...$ \Comment{branching, pruning, and merging procedures}  % \footnotemark
			\For{$f \gets 1, n_h$}
				\State calculate $\mathbf{K}_f(k)$ (\ref{eq:Kfk}) \Comment{KF updates}
				\State calculate $\mathbf{\hat{x}}_f(k \mid k), \mathbf{\hat{y}}_f(k \mid k)$ (\ref{eq:xfkyfk_hat})
				\State calculate $\mathbf{P}_f(k \mid k)$ (\ref{eq:Pkf-stab})
			\EndFor
			\State calculate $\mathbf{\hat{x}}(k \mid k), \mathbf{\hat{y}}(k \mid k)$ (\ref{eq:xkyk_hat}) \Comment{States and output estimate}
			\State calculate $\mathbf{P}(k \mid k)$ (\ref{eq:Pk_MKF}) \Comment{Error covariance}  % \footnotemark
			\For{$f \gets 1, n_h$}
				\State calculate $\mathbf{\hat{x}}_f(k+1 \mid k)$ (\ref{eq:xfkp1_hat}) \Comment{KF state predictions}
				\State calculate $\mathbf{P}_f(k+1 \mid k)$ (\ref{eq:Pfkp1})
			\EndFor
			\EndFor
		\end{algorithmic}
\end{algorithm}

% Version with footnotes - not working
%\begin{algorithm}
%	\caption{Multiple model observer calculations} \label{alg:afmm}
%	%\algorithmfootnote{$y_0$ denotes the initial value.}
%	\begin{algorithmic}
%		\Require $\mathbf{A},\mathbf{B},\mathbf{C},\mathbf{\hat{x}}(0), \mathbf{P}(0), \mathcal{Q}, \mathbf{R}, \epsilon, \mathbf{U}(N), \mathbf{Y}_M(N)$
%		\State $\mathbf{\hat{x}}_1(0) \gets \mathbf{\hat{x}}(0)$  \Comment{Initialize Kalman filters\footnotemark}
%		\State $\mathbf{P}_1(0) \gets \mathbf{P}(0)$
%		\State $\Pr(\Gamma_1(k-1)|\mathbf{Y}_M(k-1))) \gets 1$
%		\For{$f \gets 2, n_h$}
%		\State $\mathbf{\hat{x}}_f(0) \gets \mathbf{\hat{x}}(0)$
%		\State $\mathbf{P}_f(0) \gets 10^{10}\mathbf{P}(0)$
%		\State $\Pr(\Gamma_f(k-1)|\mathbf{Y}_M(k-1))) \gets 1^{-10}$
%		\EndFor
%		\For{$k \gets 0, N$}
%		\State $\Gamma_f(k), \mathbf{\hat{x}}_f(k), \mathbf{P}_f(k) \gets ...$ \Comment{Sub-optimal procedure occurs here\footnotemark}
%		\For{$f \gets 1, n_h$}
%		\State calculate $\Pr(\Gamma_f(k) \mid \mathbf{Y}_M(k))$ (\ref{eq:Pr_Gammak_given_Ykm1}, \ref{eq:p_yk_given_Gammak_Ykm1}, \ref{eq:Pr_Gammak_given_Yk}, \ref{eq:qfk})
%		\State calculate $\mathbf{K}_f(k)$ (\ref{eq:Kf}) \Comment{Filter updates}
%		\State calculate $\mathbf{\hat{x}}_f(k+1 \mid k)$ (\ref{eq:xfkp1_hat})
%		\State update $\mathbf{P}_f(k+1 \mid k)$ (\ref{eq:Pfk})
%		\EndFor
%		\State calculate $\mathbf{\hat{x}}(k+1 \mid k)$ (\ref{eq:xkyk_hat}) \Comment{State estimate}
%		\State calculate $\mathbf{P}(k+1 \mid k)$ \Comment{Error covariance\footnotemark}
%		\EndFor
%	\end{algorithmic}
%\end{algorithm}
%
%\addtocounter{footnote}{-3} %3=n
%\stepcounter{footnote}\footnotetext{To initialize the bank of $n_h$ Kalman filters, initialize one with an available estimate and covariance of the initial state of the system and set the covariances of all others to high values to ensure they are eliminated as soon as better estimates are available.}
%\stepcounter{footnote}\footnotetext{At this point, the algorithm must extend the shock indicator sequences to the current time instant, while limiting the total number of hypotheses and filters according to a particular sub-optimal method such as the procedures described in section \ref{sec:pruning} and \ref{sec:fusion}.
%\stepcounter{footnote}\footnotetext{The estimation error covariance is not required by the algorithm. It may be calculated if needed.}

The multi-model observer concept can be used for state estimation of any MJLS (\ref{eq:MJLS}) with switching $\mathbf{A}$, $\mathbf{B}$, $\mathbf{C}$, $\mathbf{D}$, $\mathbf{w}_p(k)$, or $\mathbf{e}_p(k)$. However, the number of independently-switching components is severely limited in practice due to the number of hypotheses that would need to be simulated by the observer.

\subsection{Sub-optimal algorithms} \label{sec:sub-opt}

The problem that sub-optimal algorithms address is the inevitable growth in the number of hypotheses that would have to be modelled in an optimal multi-model observer. For a system with one \gls{RODD} disturbance, the number of possible hypotheses doubles at each time step because each current hypothesis branches into twoâ€”one corresponding to the assumption of no shock in the next time period and the other to that of a shock. Figure \ref{fig:mm-obs-br} illustrates that after 3 time instants starting at $k=0$, eight hypotheses are needed to represent the possible shock sequences. For a system with two independent \gls{RODD} disturbances, the number would be 64.

\begin{figure}[ht]
	\centering
	\includegraphics[height=7.5cm]{images/mm_obs_seq_br.pdf}
	\caption{Sequence branching}
	\label{fig:mm-obs-br}
\end{figure}

\subsubsection{Generalised pseudo-Bayes algorithm} \label{sec:GPB}

One of the simplest sub-optimal multiple-model methods is the \textit{generalised pseudo-Bayesian algorithm} \citep{buxbaum_recursive_1969, jaffer_estimation_1971, tugnait_detection_1982}. Although not used directly in this work, the method is described here because it is a starting point for understanding hypotheses branching and merging, which are techniques used in the sequence fusion algorithm described by \cite{robertson_detection_1995}.

There are two basic versions of the algorithm, the first-order generalised pseudo-Bayesian estimator (\gls{GPB1}), and the second order generalised pseudo-Bayesian estimator (\gls{GPB2}). Figure \ref{fig:mm-obs-gpb1} shows a simplified diagram of the \gls{GPB1} process in the case of a system with two modes ($\gls{nj}=2$). A single estimate of the system states and error covariance at time $k$ is branched into \gls{nj} hypotheses representing the possible modes of the system at that time. In this context, \textit{branching} simply means duplicating or cloning the hypothesis state estimates and error covariance into \gls{nj} copies. These are then used to initialise \gls{nj} Kalman filters. Each Kalman filter then makes a prediction of the states in the next time instant using the system model associated with one of the possible modes. In the next time instant, the \gls{nj} predictions are corrected using the measurements, and the updated estimates are merged into a single set of estimates. The final merged estimates at each time $k$ are calculated using the multi-model observer merging procedure described in the previous section (\ref{eq:xkyk_hat_MKF},\ref{eq:Pk_MKF}). These branching and merging steps are then repeated each subsequent time step.

\begin{figure}[ht]
	\centering
	\includegraphics[height=5cm]{images/mm_obs_seq_gpb1.pdf}
	\caption{Simplified diagram of the \gls{GPB1} algorithm ($n_j=2$)}
	\label{fig:mm-obs-gpb1}
\end{figure}

Whereas the \gls{GPB1} estimator considers \gls{nj} possible mode transitions from time $k-1$ to time $k$, the \gls{GPB2} estimator considers $\gls{nj}^2$ possible transition sequences from time $k-2$ to time $k$. Figure \ref{fig:mm-obs-gpb2} shows a simplified diagram of the \gls{GPB2} algorithm in the case of two modes ($\gls{nj}=2$). At time $k$ it maintains \gls{nj} merged estimates and associated variables, $\left\{ \hat{\mathbf{x}}_m(k \mid k), \mathbf{P}_m(k \mid k), \hat{\mathbf{y}}_m(k \mid k), \Pr(\Gamma_m(k) \mid \mathbf{Y}_M(k)) \right\}$, for $m=1,2,...,\gls{nj}$. Each of these is then branched into \gls{nj} estimates, creating a total of $\gls{nh}=\gls{nj}^2$ hypotheses, represented by \gls{nh} Kalman filters labelled $f=1,2,...\gls{nh}$. At time $k+1$, the Kalman filter predictions are corrected to produce \gls{nh} estimates. Then two merging operations are carried out on these estimates. The first merges the \gls{nh} estimates into $\gls{nm}=\gls{nj}$ estimates for use in the next step. The second merges the \gls{nm} merged estimates again, into one final estimate which is the output of the observer and is not used in subsequent steps.
\begin{figure}[ht]
	\centering
	\includegraphics[height=6.5cm]{images/gpb2_diagram.pdf}
	\caption{Simplified diagram of the \gls{GPB2} algorithm ($n_j=2$)}
	\label{fig:mm-obs-gpb2}
\end{figure}

The \gls{nm} merged estimates and covariances at time $k$ are produced by calculating weighted sums of the estimates and covariances of the branched hypotheses
\begin{equation} \label{eq:xmkymk_hat_MKF}
	\begin{aligned}
		\glsadd{xmk_hat}\mathbf{\hat{x}}_m(k \mid k) = \frac{1}{Z_m(k)} \sum_{f \in \mathcal{H}_{\text{merge},m}} \mathbf{\hat{x}}_f(k \mid k) \Pr(\Gamma_f(k) \mid \mathbf{Y}_M(k)), \\
		\glsadd{ymk_hat}\mathbf{\hat{y}}_m(k \mid k) = \frac{1}{Z_m(k)} \sum_{f \in \mathcal{H}_{\text{merge},m}} \mathbf{\hat{y}}_f(k \mid k) \Pr(\Gamma_f(k) \mid \mathbf{Y}_M(k)),\\
		\glsadd{Pmk}\mathbf{P}_m(k \mid k) = \frac{1}{Z_m(k)} \sum_{f \in \mathcal{H}_{\text{merge},m}} \Pr(\Gamma_f(k) \mid \mathbf{Y}_M(k)) \left( \mathbf{P}_f(k \mid k) + \delta_\mathbf{\hat{x}}(k) \delta_\mathbf{\hat{x}}^\intercal(k) \right), \\
		\delta_\mathbf{\hat{x}}(k) = \mathbf{\hat{x}}(k \mid k) - \mathbf{\hat{x}}_f(k \mid k), \\
		\Pr(\Gamma_m(k) \mid \mathbf{Y}_M(k)) = \sum_{f \in \mathcal{H}_{\text{merge},m}} \Pr(\Gamma_f(k) \mid \mathbf{Y}_M(k)).
	\end{aligned}
\end{equation}
where \gls{Hmerge} is a set of \gls{nm} indices that determine which hypotheses are merged to produce each merged estimate, and \gls{Zmk} is a scalar normalization variable given by
\begin{equation} \label{eq:Zmk}
	Z_m(k) = \sum_{f \in \mathcal{H}_{\text{merge},m}} \Pr(\Gamma_f(k) \mid \mathbf{Y}_M(k)).
\end{equation}

In the case of \gls{GPB2}, \gls{Hmerge} is defined
\begin{equation} \label{eq:Hmerge_GPB2}
	\mathcal{H}_{\text{merge}} = \begin{Bmatrix} \mathcal{H}_{\text{merge},1} \\ \mathcal{H}_{\text{merge},2} \end{Bmatrix} = \begin{Bmatrix}
		\begin{bmatrix}	1 \\ 3 \end{bmatrix} \\
		\begin{bmatrix}	2 \\ 4 \end{bmatrix}
	\end{Bmatrix}.
\end{equation}
This means that merged estimate $\mathbf{\hat{x}}_1(k \mid k)$ is calculated by merging the estimates associated with branched hypotheses 1 and 3, and merged estimate $\mathbf{\hat{x}}_2(k \mid k)$ is calculated by merging the estimates of branched hypotheses 2 and 4.

An associated index, \gls{Hbranch}, governs the branching operation, which for \gls{GPB2} is
\begin{equation} \label{eq:Hbranch_GPB2}
	\mathcal{H}_{\text{branch}} = \begin{bmatrix} 1 \\ 1 \\ 2 \\ 2 \end{bmatrix}.
\end{equation}
This indicates that branched estimates 1 and 2 are clones of merged estimate $\mathbf{\hat{x}}_1(k \mid k)$ and branched estimates 3 and 4 are clones of merged estimate $\mathbf{\hat{x}}_2(k \mid k)$. These definitions match the branching and merging operations depicted in Figure \ref{fig:mm-obs-gpb2}.

% TODO: We don't need this if we define the r(k) and r_m(k) transitions.
The system modes, which determine the system model parameters as well as the mode transition probabilities, evolve according to the branching and merging indices. Starting with the modes associated with the merged hypotheses at time $k$, which in the case of GPB2 are
\begin{equation} \label{eq:rmk_GPB2}
		\glsadd{rmk}\mathbf{r}_m(k) = \begin{bmatrix} 1 \\ 2 \end{bmatrix},
\end{equation}
the branched modes after branching at time $k$ and before merging at time $k+1$ are
\begin{equation} \label{eq:rbk_GPB2}
	\begin{aligned}
		\glsadd{rb2k}\mathbf{r}_{b,2}(k) &= \begin{bmatrix} 1 \\ 1 \\ 2 \\ 2 \end{bmatrix},
		\glsadd{rb1k}\mathbf{r}_{b,1}(k+1) &= \begin{bmatrix} 1 \\ 2 \\ 1 \\ 2 \end{bmatrix}.
	\end{aligned}
\end{equation}
Note that \gls{rb2k} is derived by branching \gls{rmk} using \gls{Hbranch} and that when $\mathbf{r}_{b,1}(k+1)$ is merged using \gls{Hmerge} in the next time step, it leads to 
\begin{equation} \label{eq:rmkp1rmk_GPB2}
	\mathbf{r}_m(k+1) = \begin{bmatrix} 1 \\ 2 \end{bmatrix} = \mathbf{r}_m(k).
\end{equation}
Due to this condition, the algorithm is consistent when executed consecutively every time step.

The advantages of the \gls{GPB1} and \gls{GPB2} estimators are their simplicity, the fact that they can be applied to any switching system, and that the number of hypotheses ($n_j$ or $n_j^2$) is finite and constant, which limits computational requirements. The disadvantages include the fact that they model every possible transition over one or two time steps and merge these into a reduced set of estimates before the next iteration. 

While the branching, modes, and merging steps of the \gls{GPB1} and \gls{GPB2} algorithms are the same each time step, they may be time-varying in the case of the sub-optimal multiple-model algorithms considered in this work. The notation above is easily extended to more complex algorithms with arbitrary branching and merging steps by allowing \gls{Hbranch}, \gls{Hmerge}, \gls{rb1k}, and \gls{rb2k} to be time-varying and by allowing an arbitrarily large number of branched and merged hypotheses, \gls{nh} and \gls{nm}, to exist at each time instant.

\subsubsection{Sequence fusion} \label{sec:fusion}

\cite{robertson_detection_1995} proposed a sub-optimal approach that combines three approximation techniques specifically intended for \gls{RODD} state estimation. The first is referred to as \textit{sequence fusion}. This is based on the assumption that only recent differences in the hypothesis sequences are important for state estimation. Therefore, sequences that are identical over the previous \gls{nf} sample times may be merged, where \gls{nf} is known as the \textit{fusion horizon}.
%The same techniques used in the generalized pseudo-Bayes algorithm are used to perform the sequence branching and merging at each time step. The differences are that more than $n_j^2$ hypotheses are maintained and these are based on longer, pre-specified sequences of possible shocks.

Rather than allowing the number and length of the shock indicator hypothesis sequences, $\Gamma_f(k)$, to grow indefinitely, a fixed number of sequences of length \gls{nf} sample periods are defined, consisting of only the current and the previous $\gls{nf}-1$ values of $\gamma(k)$
\begin{equation} \label{eq:Gamma_kmf_k}
	\glsadd{Gammafkmnk}\Gamma_m(k-N_f+1,k)=\{\gamma_m(k-N_f+1), ...,  \gamma_m(k-1), \gamma_m(k)\}, m=1,2,..., \gls{nm}.
\end{equation}
These fixed-length sequences are used to merge similar hypotheses so that the total number remains the same from one time step to the next.

Secondly, they assume that the exact timing of random shocks is not important and define \textit{detection intervals} of more than one sample period during which it is assumed that only one shock may occur. This is based on the observation that when the correction gain of a Kalman filter increases due to the assumption of a shock occurrence ($\gamma_m(k)=1$), it tends to remain large for several sample periods. The probability of at least one random shock during a detection interval of length \gls{d} samples is therefore higher than the probability, \gls{epsilon}, of a single shock in one sample period, and is given by
\begin{equation}  \label{eq:p_gamma_d}
	\glsadd{epsilond}\epsilon_d = 1 - (1 - \epsilon)^{\gls{d}}.
\end{equation}

The occurrence of one or more shocks within a detection interval is then represented by a single shock at the start of the detection interval and the probabilities of a shock at any other time are set to zero,
\begin{equation} \label{eq:Pr_gamma_nd}
	\begin{aligned}
		\Pr\left(\gamma_{f}(k)=0\right) = \begin{cases*}
			1 - \epsilon_d & \text { for } $k = \gls{d}, 2\gls{d}, 3\gls{d}, \ldots$ \\
			1 & \text { for } $k \ne \gls{d}, 2\gls{d}, 3\gls{d}, \ldots$
		\end{cases*} \\
		\Pr\left(\gamma_{f}(k)=1\right) = \begin{cases*}
			\epsilon_d & \text { for } $k = \gls{d}, 2\gls{d}, 3\gls{d}, \ldots$ \\
			0 & \text { for } $k \ne \gls{d}, 2\gls{d}, 3\gls{d}, \ldots$
		\end{cases*} \\
	\end{aligned}
\end{equation}

Thirdly, they rely on the fact that the random shocks occur infrequently and therefore the probability of more than \gls{m} shocks during the fusion horizon is low, where \gls{m} may be 1 or some other low number. This further reduces the number of possible hypotheses that must be modelled.

To illustrate the resulting shock hypothesis sequences, consider an example. Suppose there is one \gls{RODD} to estimate. A sequence fusion algorithm is used with a fusion horizon of $\gls{nf}=9$, a detection interval of $\gls{d}=3$, and a maximum number of shocks over the fusion horizon of $\gls{m}=1$. Figure \ref{fig:mm-obs-seq-SFex1} shows the four shock hypotheses that would be required in this case. Note that hypothesis 1 assumes no shocks at any time. Hypothesis 2 assumes shocks occur at times $k=0,9,18,...$. Hypothesis 3 assumes shocks occur at times $k=3,12,21,...$, and so on. After $\gls{nf}=9$ sample periods, the sequences repeat indefinitely.

\begin{figure}[ht]
	\centering
	\includegraphics[width=13.5cm]{images/mm_obs_seq_rob1.pdf}
	\caption{Sequence fusion example 1 ($\gls{nf}=9$, $\gls{m}=1$, $\gls{d}=3$)}
	\label{fig:mm-obs-seq-SFex1}
\end{figure}

Suppose that a shock actually occurred in the system at time $k=4$. In this case, the algorithm should predict that hypothesis 3 is the most likely because this assumes a shock occurred at $k=3$, which is the closest to the actual time.

Figure \ref{fig:mm-obs-seq-SFex2} illustrates a second example with $\gls{nf}=10$, $n_\text{max}=2$, and $\gls{d}=5$. This also has four hypotheses. However, note that hypothesis 4 accounts for the possibility of two shocks within the fusion horizon. As in the previous example, if a true shock occurred at time $k=4$, the most likely hypothesis should be hypothesis 3 because it assumes a shock occurred at $k=5$, which is close to the actual time.

\begin{figure}[ht]
	\centering
	\includegraphics[width=13.5cm]{images/mm_obs_seq_rob2.pdf}
	\caption{Sequence fusion example 2 ($\gls{nf}=10$, $\gls{m}=2$, $\gls{d}=5$)}
	\label{fig:mm-obs-seq-SFex2}
\end{figure}

As mentioned, the shock hypothesis sequences over the fusion horizon, \gls{Gammafkmnk}, determine the branching and merging operations that occur at each time step. The logic is as follows: (i) at time $k$, branch each hypothesis sequence into the possible mode transitions that occur between time $k$ and $k+1$, (ii) advance the branched sequences into the next time step, according to the possible mode transitions, (iii) compare the branched sequences and merge those that are identical over the new fusion horizon from time $k-\gls{nf}+2$ to $k+1$.

Consider again the sequences from the previous example in Figure \ref{fig:mm-obs-seq-SFex2}. By applying the logic described above, the branching and merging operations depicted in Figure \ref{fig:mm-obs-seq-sf95} may be deduced. For example, consider what happens at time $k=9$. At this time, the fusion horizon spans from time 0 to 9. The four sequences are branched into 8 and advanced to the next time instant according to the possible modes at that time (no shock, shock). Then, at time $k=10$ the 8 branched hypotheses are merged back to 4 by combining sequences that are identical over the new fusion horizon, which spans from $k=1$ to 10. Note that by applying this logic each time step, branching and merging are only required once every 5 time steps when shocks are assumed to be possible.
\begin{figure}[ht]
	\centering
	\includegraphics[width=15.5cm]{images/mm_obs_seq_sf95.pdf}
	\caption{Sequence branching and merging example ($\gls{nf}=10$, $\gls{m}=2$, $\gls{d}=5$)}
	\label{fig:mm-obs-seq-sf95}
\end{figure}

Rather than constant branching and merging indices, as in GPB2 (\ref{eq:Hbranch_GPB2},\ref{eq:Hmerge_GPB2}), sequences of branching and merging indices are needed. In this example, they are
\begin{equation} \label{eq:Hbranch_SFex2}
	\mathcal{H}_{\text{branch}} = \begin{Bmatrix}
		\begin{bmatrix} 1 \\ 2 \\ 3 \\ 4 \end{bmatrix} &
		\begin{bmatrix} 1 \\ 2 \\ 3 \\ 4 \end{bmatrix} &
		\begin{bmatrix} 1 \\ 2 \\ 3 \\ 4 \end{bmatrix} &
		\begin{bmatrix} 1 \\ 2 \\ 3 \\ 4 \end{bmatrix} &
		\begin{bmatrix} 1 \\ 1 \\ 2 \\ 2 \\ 3 \\ 3 \\ 4 \\ 4 \end{bmatrix} &
		\begin{bmatrix} 1 \\ 2 \\ 3 \\ 4 \end{bmatrix} &
		\begin{bmatrix} 1 \\ 2 \\ 3 \\ 4 \end{bmatrix} &
		\begin{bmatrix} 1 \\ 2 \\ 3 \\ 4 \end{bmatrix} &
		\begin{bmatrix} 1 \\ 2 \\ 3 \\ 4 \end{bmatrix}
		\begin{bmatrix} 1 \\ 1 \\ 2 \\ 2 \\ 3 \\ 3 \\ 4 \\ 4 \end{bmatrix} &
	\end{Bmatrix},
\end{equation}
and
\begin{equation} \label{eq:Hmerge_SFex2}
	\mathcal{H}_{\text{merge}} = \begin{Bmatrix}
		\begin{bmatrix}	1 \\ 3 \end{bmatrix} & 1 & 1 & 1 & 1 & \begin{bmatrix}	1 \\ 5 \end{bmatrix} & 1 & 1 & 1 & 1 \\
		\begin{bmatrix}	2 \\ 4 \end{bmatrix} & 2 & 2 & 2 & 2 & \begin{bmatrix}	3 \\ 7 \end{bmatrix} & 2 & 2 & 2 & 2 \\
		\begin{bmatrix}	5 \\ 7 \end{bmatrix} & 3 & 3 & 3 & 3 & \begin{bmatrix}	2 \\ 6 \end{bmatrix} & 3 & 3 & 3 & 3 \\
		\begin{bmatrix}	6 \\ 8 \end{bmatrix} & 4 & 4 & 4 & 4 & \begin{bmatrix}	4 \\ 8 \end{bmatrix} & 4 & 4 & 4 & 4 \\
	\end{Bmatrix}.
\end{equation}

% Remove these: they don't add anything since these can be derived from the sequence
% and the branching/merging indices. Also, this convention for \Gamma_b and \Gamma_m
% was not defined. \Gamma_f was defined as single sequence and arguably would be
% better restricted to the merged sequences, than the branched ones.
%Likewise, the merged and branched shock (mode) indicator sequences are
%\begin{multline} \label{eq:Gamma_km09}
%	\glsadd{Gammafkmnk}\Gamma_m(0,9) = \left\{
%		\mathbf{\gamma}_m(0), \mathbf{\gamma}_m(1), \cdots, \mathbf{\gamma}_m(9)
%	\right\} = \\ 
%	\left\{
%		\begin{bmatrix} 0 \\ 1 \\ 0 \\ 1 \end{bmatrix},
%		\begin{bmatrix} 0 \\ 0 \\ 0 \\ 0 \end{bmatrix},
%		\begin{bmatrix} 0 \\ 0 \\ 0 \\ 0 \end{bmatrix},
%		\begin{bmatrix} 0 \\ 0 \\ 0 \\ 0 \end{bmatrix},
%		\begin{bmatrix} 0 \\ 0 \\ 0 \\ 0 \end{bmatrix},
%		\begin{bmatrix} 0 \\ 0 \\ 1 \\ 1 \end{bmatrix},
%		\begin{bmatrix} 0 \\ 0 \\ 0 \\ 0 \end{bmatrix},
%		\begin{bmatrix} 0 \\ 0 \\ 0 \\ 0 \end{bmatrix},
%		\begin{bmatrix} 0 \\ 0 \\ 0 \\ 0 \end{bmatrix},
%		\begin{bmatrix} 0 \\ 0 \\ 0 \\ 0 \end{bmatrix}
%	\right\}.
%\end{multline}
%\begin{multline} \label{eq:Gamma_kb09}
%		\Gamma_b(0,9 \mid 9) = \left\{\mathbf{\gamma}_b(0 \mid 0), \mathbf{\gamma}_b(1 \mid 1), \cdots, \mathbf{\gamma}_b(9 \mid 9) \right\} = \\
%		\left\{
%			\begin{bmatrix} 0 \\ 0 \\ 0 \\ 0 \end{bmatrix},
%			\begin{bmatrix} 0 \\ 0 \\ 0 \\ 0 \end{bmatrix},
%			\begin{bmatrix} 0 \\ 0 \\ 0 \\ 0 \end{bmatrix},
%			\begin{bmatrix} 0 \\ 0 \\ 0 \\ 0 \end{bmatrix},
%			\begin{bmatrix} 0 \\ 0 \\ 0 \\ 0 \\ 1 \\ 1 \\ 1 \\ 1 \end{bmatrix},
%			\begin{bmatrix} 0 \\ 0 \\ 0 \\ 0 \end{bmatrix},
%			\begin{bmatrix} 0 \\ 0 \\ 0 \\ 0 \end{bmatrix},
%			\begin{bmatrix} 0 \\ 0 \\ 0 \\ 0 \end{bmatrix},
%			\begin{bmatrix} 0 \\ 0 \\ 0 \\ 0 \end{bmatrix}
%			\begin{bmatrix} 0 \\ 0 \\ 1 \\ 1 \\ 0 \\ 0 \\ 1 \\ 1 \end{bmatrix},
%		\right\},
%\end{multline}
%\begin{multline} \label{eq:Gamma_kb110}
%		\Gamma_b(1,10 \mid 9) = \left\{ \mathbf{\gamma}_b(1 \mid 0), \mathbf{\gamma}_b(2 \mid 1), \cdots, \mathbf{\gamma}_b(10 \mid 9) \right\} = \\
%		\left\{
%			\begin{bmatrix} 0 \\ 1 \\ 0 \\ 1 \\ 0 \\ 1 \\ 0 \\ 1 \end{bmatrix},
%			\begin{bmatrix} 0 \\ 0 \\ 0 \\ 0 \end{bmatrix},
%			\begin{bmatrix} 0 \\ 0 \\ 0 \\ 0 \end{bmatrix},
%			\begin{bmatrix} 0 \\ 0 \\ 0 \\ 0 \end{bmatrix},
%			\begin{bmatrix} 0 \\ 0 \\ 0 \\ 0 \end{bmatrix},
%			\begin{bmatrix} 0 \\ 1 \\ 0 \\ 1 \\ 0 \\ 1 \\ 0 \\ 1 \end{bmatrix},
%			\begin{bmatrix} 0 \\ 0 \\ 0 \\ 0 \end{bmatrix},
%			\begin{bmatrix} 0 \\ 0 \\ 0 \\ 0 \end{bmatrix},
%			\begin{bmatrix} 0 \\ 0 \\ 0 \\ 0 \end{bmatrix},
%			\begin{bmatrix} 0 \\ 0 \\ 0 \\ 0 \end{bmatrix}
%		\right\}.
%\end{multline}
Although the number of branched hypotheses is time-varying, after \gls{nf} time steps the sequences repeat such that 
\begin{equation} \label{eq:rmkrmkmNf_SFex2}
	\mathbf{\gamma}_m(k) = \mathbf{\gamma}_m(k-\gls{nf}).
\end{equation}

As in the \gls{GPB2} algorithm, the overall estimates of the system states and outputs, \gls{xk_hat} and \gls{yk_hat}, are calculated by merging the partially-merged estimates into one overall estimate. This is achieved by substituting \gls{xmk_hat} and \gls{ymk_hat} for \gls{xfk_hat} and \gls{yfk_hat} in (\ref{eq:xkyk_hat_MKF}).

\cite{robertson_detection_1995} describe a systematic procedure to choose the parameters \gls{nf}, \gls{m}, and \gls{d} and give the formula for the total probability of the modelled hypotheses as
\begin{equation} \label{eq:p_gamma}
	\glsadd{beta}\gls{beta}=\operatorname{Pr}\left(\sum_{i=1}^{n} \gamma(i \gls{d}) \leq \gls{m} \right) = \sum_{j=0}^{\gls{m}} \binom{n}{j} \epsilon_d^{n-j}(1-\epsilon_d)^{j},
\end{equation}
where $\binom{n}{j}$ represents the number of possible combinations of $j$ shocks in $n$ detection intervals. They recommend that the total probability should be at least 0.99 to ensure that only low-probability hypotheses are ignored.

In a later journal paper, \cite{robertson_method_1998} describe a variation to the sequence fusion algorithm described above.  Rather than assuming that the shock occurs in the first sample period of each detection interval, as shown in Figures \ref{fig:mm-obs-seq-SFex1} and \ref{fig:mm-obs-seq-SFex2}, they propose to represent the possibility of a shock as a sequence of \gls{d} smaller shocks such that the total variance over the detection interval is the same as that of one shock. They claimed this improved the performance of the algorithm in their simulations.

To implement this modification, define a new variable, $\delta(n)$, to represent whether or not at least one shock occurred during the $n$\textsuperscript{th} detection interval:

\begin{equation} \label{eq:deltak}
	\delta(n) = \begin{cases*}
		0 & \text{if} $\sum_{k=(n-1) \gls{d}}^{n \gls{d} - 1}{\gls{gammak}} = 0$, \\
		1 & \text{if} $\sum_{k=(n-1) \gls{d}}^{n \gls{d} - 1}{\gls{gammak}} \ge 1$.
	\end{cases*}
\end{equation}

Then, replace the random shock variable used at each sample time, \gls{wpk} (\ref{eq:wpk2}), with:
\begin{equation} \label{eq:wpdk}
	w_{p,d}(k) \sim 
	\begin{cases*}
		\mathcal{N}\left(0, \gls{sigmawp2}\right) & \text{when} $\delta(n) = 0$, \\
		\mathcal{N}\left(0, \frac{\gls{b}^2\gls{sigmawp2}}{\gls{d}}\right) & \text{when} $\delta(n) = 1$.
	\end{cases*}
\end{equation}

Note that the variance of a single shock, $\gls{b}^2\gls{sigmawp2}$, is divided by the detection interval length \gls{d}. In this version of the algorithm, the branching and merging procedure is only carried out at the end of each detection interval. In the steps within the detection interval, the Kalman filters are updated using the measurements, but no branching or merging occurs.

Figure \ref{fig:mm-obs-seq-sf98} shows the shock hypothesis sequences and the merging and branching steps of the 1998 version of the sequence fusion algorithm with the same parameters as in the previous example.
\begin{figure}[ht]
	\centering
	\includegraphics[width=15cm]{images/mm_obs_seq_sf98.pdf}
	\caption{Sequence branching and merging example â€“ 1998 version ($N_d=5$, $n_\text{max}=2$, $N_f=10$)}
	\label{fig:mm-obs-seq-sf98}
\end{figure}
Note the two main differences when compared to Figure \ref{fig:mm-obs-seq-sf95}. Firstly, the system mode indicators are the same throughout the detection interval, whereas in the 1995 version the shocks were assumed to occur only at the first sample time of each detection interval. Secondly, note that after branching, the \gls{nh} hypotheses are maintained for the duration of the detection interval before being merged and branched at the last sample time. The idea of these modifications is to allow $N_d$ Kalman filter updates to occur with the adjusted shock probability and variance (\ref{eq:p_gamma_d}, \ref{eq:wpdk}) before evaluating and merging the estimates. This is expected to produce better estimates of the hypothesis probabilities in situations where it takes more than one time step to detect changes in the system.

\subsubsection{Sequence pruning} \label{sec:pruning}

\textit{Sequence pruning} is the selective deletion of shock hypotheses that have a low likelihood given the current measurements. \cite{eriksson_classification_1996} used the \textit{adaptive forgetting through multiple models} \gls{AFMM}) algorithm by \cite{andersson_adaptive_1985} for \gls{RODD} estimation. The \gls{AFMM} uses sequence pruning to limit the number of filters. In this algorithm, the current hypotheses at each time step are ranked according to their conditional probabilities (\ref{eq:Pr_Gammak_given_Yk}). The hypothesis with the lowest probability is then pruned with the caveat explained below. The most probable hypothesis is allowed to branch but all other hypotheses are advanced assuming no shock occurs in the next time period (i.e. all but one of their branches are pruned). This makes sense in the case of \gls{RODD} disturbances because the probability of a shock is low. Thus, the total number of hypotheses and filters is capped at a fixed number, \gls{nh}.

The caveat mentioned above, is that no hypothesis may be eliminated less than \gls{nmin} time steps after being created. This is to prevent good hypotheses from being eliminated before the conditional probabilities have been properly estimated, which can take more than one sample period. For this reason, \gls{nh} must be at least sufficient to accommodate the \textit{minimum life}, \gls{nmin}, of all new hypotheses. Note that in the case of systems with more than one \gls{RODD} disturbance, the number of branches of the most likely sequence is more than two, therefore a larger number of sequences will be pruned at each sample time.

To illustrate the sequence pruning procedure, consider the diagram in Figure \ref{fig:mm-obs-seq-SP}. This shows one possible evolution of the hypothesis sequences in response to an actual shock sequence consisting of one shock at time $k=4$.  The most likely hypotheses at each time instant, identified by the circles with thicker outlines, branch into two at the next time instant. After the limit of five hypotheses is reached, one hypothesis is pruned at each sample time and replaced by a new branched hypothesis at the next. Note that at time $k=6$, hypothesis 2 becomes the most likely based on the available measurements at that time. Also note that no new branches are terminated in less than two sample times.

\begin{figure}[ht]
	\centering
	\includegraphics[width=10.7cm]{images/mm_obs_seq_SP.pdf}
	\caption{Sequence pruning example ($n_h=5$, $N_\text{min}=2$)}
	\label{fig:mm-obs-seq-SP}
\end{figure}

The \gls{AFMM} algorithm by \cite{gustafsson_estimation_1993} includes a procedure for online estimation of the measurement noise covariance using a forgetting factor to control the speed of adaptation of the estimates. This component was not implemented in this work since it is assumed the measurement noise is time invariant.

\subsubsection{Implementation details} \label{sec:implementation}

The diagram in Figure \ref{fig:mkf-infoflow} depicts the general computation steps and information flows of the sub-optimal multi-model observers, as implemented in this work. The solid black rectangles represent the computation steps and the white circles represent the main variables. Steps 1 and 2 are the prediction steps of the Kalman filters (\ref{eq:xfkp1_hat}, \ref{eq:yfk_pred}), step 3 is the calculation of the prior probabilities of the hypotheses (\ref{eq:Pr_Gammak_given_Ykm1}), step 4 is the hypotheses evaluation step (\ref{eq:Pr_Gammak_given_Yk}, \ref{eq:qfk}), and step 5 is the Kalman filter update step (\ref{eq:xfkyfk_hat}, \ref{eq:Pkf-stab}). Step 6 is a place-holder for the sub-optimal procedures which depend on the specific algorithm but in this work include some combination of sequence pruning, merging and branching. During this step, the final estimates of the states and outputs are also calculated.

\begin{figure}[ht]
	\centering
	\includegraphics[width=15.5cm]{images/mkf_infoflow.pdf}
	\caption{General information flow diagram of a multiple-model observer}
	\label{fig:mkf-infoflow}
\end{figure}

At time $k$, the algorithm requires a mode indicator vector, $\gls{gammak}=\begin{bsmallmatrix} \gamma_1(k) & \cdots & \gamma_{n_h}(k) \end{bsmallmatrix}^\intercal$, the system output measurement, \gls{yMk}, and input, \gls{uk}, and produces estimates of the states, \gls{xk_hat}, and outputs, \gls{yk_hat}. The mode indicator vector is either constant, as in the case of the \gls{GPB1} and \gls{GPB2} algorithms or is specified by the sub-optimal procedure at each time step. At the end of each time step, the mode indicator vector, conditional hypothesis probabilities, one-step-ahead state predictions, and the prediction error covariances for each hypothesis are stored for use in the next time step. The sub-optimal algorithm, which determines \gls{gammak} as well as the merging, pruning, and branching procedures in step 6, may have other variables that need to be stored. These are not shown on the diagram. The total number of hypotheses modelled,\gls{nh}, also depends on the algorithm, and may be time-varying.

\section{System identification} \label{sec:sys-id}
%
%$TODO: Not complete.
%

% Some text not used in IFAC report
Model-based observers such as the Kalman filter require a dynamic model of the process. In practice, models of the process dynamics are not available but they can be identified when input-output data sampled from the process is available. In this case, system identification methods are common practice and described by \cite{ljung_system_1999} among others.

To construct a multi-model observer for \gls{RODD} estimation, the structure and parameters of the process model as well as the disturbance model are needed. \gls{RODD}s are discrete-time \textit{Markov jump linear systems} (\gls{MJLS}) \citep{costa_discrete-time_2005}. Standard approaches to system identification such as least-squares regression are not applicable to hybrid dynamical systems with both discrete and continuous states. Identification of these types of systems is challenging and the subject of ongoing research. See for example, \cite{piga_estimation_2020}.

%Outline notes:
%\begin{itemize}
%	\item Explain Isaksson and Eriksson's perspective on standard system identification approach.
%	\item Explain distinction between system detection or `discrimination' and system identification, reference Isaksson and Eriksson's paper on disturbance classification (whether disturbance at input or output of process).
%	\item Introduce other approachesâ€”MLE, EM algorithm (Dempster et al., Wong \& Lee)
%	\item Methods proposed by Bemporad (Fitting jump models, 2018 and Jump Box-Jenkins, 2020).
%	\item Theory and challenges Costa book. Others?
%	\item In recent years, numerical methods to overcome the intractability of the probabilistic integral have received a lot of attention.
%	\item Sequential Monte-Carlo methods, (incl. particle filtering), Stochastic Variational Inference, ... (read Special issue in IEEE control magazine for an overview of these methods)
%\end{itemize}

% More text from IAFAC paper:
%are assumed to be known and were set to match the characteristics of the simulated disturbance. In practice, they would have to be estimated, either using prior knowledge of the disturbance source, or possibly from system output measurements using an appropriate system identification method---see \cite{schon_sequential_2015} for one possible approach---provided a sufficiently long sequence of data is available.

% Note: may remove this if we arenâ€™t using any formal methods.

%\section{Control strategies}
%
%In this work, the goal is to test the performance of different observers in a closed-loop feedback control application (not to evaluate different control strategies). Therefore, only one control strategy is considered. According to the \textit{separation principle} of estimation and control, the control strategy may be designed independently of the observer. The controller is designed using the same augmented system model, including the plant model and disturbance models, that is used in the observer design. However, the switching behaviour of the random shock variable used in the \gls{RODD} is not explicitly considered in the control design. The estimates of the model states produced by the observer are assumed to be optimal, i.e. the expected values, and their uncertainty is not taken into account by the control algorithm or in its design.
%
%
%\subsection{Model predictive control}
%
%\textit{Model predictive control} (\gls{MPC}) is a well known and widely used multi-variable control algorithm used in industrial applications. This is largely due to the fact that constraints can be imposed on the manipulated variables and control variables, as well as its intuitive design and the ease with which it can be tuned to achieve control objectives \citep{maciejowski_predictive_2002}. Although it is a computationally complex algorithm, numerous proven commercial products exist to enable its implementation.
%
%\gls{MPC} utilizes a prediction equation based on the dynamic model of the system to find feasible future trajectories of the system outputs as a function of the manipulated variables and the states of the model at the current time. The length of the prediction horizon, \gls{Hp}, is defined in terms of the number sample times starting at the next time instant, $k+1$. The predicted outputs over the prediction horizon, calculated at the current time $k$, are denoted $\hat{\textbf{y}}(k+i | k)$ for $i=1,2,...,H_p$. The length of the control horizon, \gls{Hc}, is defined starting at the current time, $k$, and the manipulated inputs are denoted $\mathbf{u}(k+i-1)$ for $i=1,2,...,H_c$. The control horizon is usually shorter than the prediction horizon, in which case, $\mathbf{u}(k+j)=\mathbf{u}(k+H_c-1)$ for $j=H_c,H_c+1,...,H_p$.
%
%The constrained optimization problem, which is solved at each time step, is
%\begin{align} \label{eq:mpc-opt}
%	\begin{split}
%		\min _{\mathbf{u}(k), \mathbf{u}(k+1), \ldots, \mathbf{u} (k+H_c-1)}
%		& \quad \sum_{i=1}^{H_{p}}[\mathbf{\hat{y}}(k+i / k) - \mathbf{r}(k+i)]^\intercal \mathbf{\Phi} [\mathbf{\hat{y}}(k+i / k) - \mathbf{r}(k+i)] \\
%		& \qquad + \sum_{i=1}^{H_{c}}[\Delta \mathbf{u}(k+i-1)]^\intercal \mathbf{\Lambda} [\Delta \mathbf{u}(k+i-1)] \\
%			\end{split} \\
%		\text { subject to: }
%		&\ \mathbf{u}_{min} \leq \mathbf{u}(k+j-1) \leq \mathbf{u}_{max} \quad  j=1,2, \dots, H_{c} \label{eq:mpc-cons-1}, \\
%		& \Delta \mathbf{u}_{min} \leq \Delta \mathbf{u}(k+j-1) \leq \Delta \mathbf{u}_{max} \quad j=1,2, \dots, H_{c}, \label{eq:mpc-cons-2} \\
%		& \mathbf{y}_{min} \leq \mathbf{\hat{y}}(k+j / k) \leq \mathbf{y}_{max} \quad  j=1,2, \dots, H_{p}, \label{eq:mpc-cons-3}
%\end{align}\textbf{[TODO: Consider including slack variables to ensure feasibility]}
%where $\mathbf{r}(k+i)$ for $i=1,2,...,H_p$ is the reference output trajectory, and $\Delta \mathbf{u}(k)$ is the change in the manipulated variable at time $k$, defined as $\Delta \mathbf{u}(k) = \mathbf{u}(k) - \mathbf{u}(k-1)$. The tunable parameters are $H_p$, $H_c$, $\mathbf{\Phi}$, and $\mathbf{\Lambda}$, and the constraints are $\mathbf{u}_{min}$, $\mathbf{u}_{max}$, $\Delta \mathbf{u}_{min}$, $\Delta \mathbf{u}_{max}$, $\mathbf{y}_{min}$, and $\mathbf{y}_{max}$. Note that the last constraint (\ref{eq:mpc-cons-3}) only guarantees that the estimate of the system output will not violate the constraints. This does not imply that the true system output will respect them at all times.
%
%Once a solution to the optimization problem is found, only the control actions at the current time, \gls{uk}, are transmitted to the plant. The procedure is then repeated every future time instant to compute the subsequent control actions. This is referred to as \textit{receding horizon control}.


\section{Grinding simulation model} \label{sec:grinding-simulator}

%Outline notes:
%\begin{outline}
%    \1 Assumptions and limitations: constant breakage rate model, relationships between speed, media, trajectories, filling level and breakage not captured.
%	\1 Describe grate, transport delays and cyclone model.
%	\1 Outline any significant changes made from Edgar's model
%	\1 Figure: simulation results showing steady-state characteristics - e.g. power, grind, and throughput vs. fill level and speed.
%	\1 Figure \ref{fig:coarse_fine_psd_plot}: Particle size distributions of feed, recirculating load and product - this should help explain steady-state characteristics.
%	\1 Figure - Step responses of main process variables to changes in ore properties.
%	\1 Selection of particle size distribution as the disturbance variable for this work.
%	\1 Steady-state characteristics with operating points (grind curves)\\
%\end{outline}

A dynamic simulation model of the primary grinding circuit of a gold mine in Quebec is used to simulate the effects of changes in ore feed properties on the grinding circuit over time. The model was developed by \cite{perez_garcia_dynamic_2020} following the methodology described by \cite{grimble_dynamic_2010} and was calibrated to match operating data collected from the plant \citep{perez-garcia_systematic_2020}. Grinding in the \gls{SAG} mill is simulated by a \textit{population balance model} with 24 discrete ore particle size intervals and constant specific-energy selection rates (i.e. breakage rates are proportional to total energy consumption) and a constant breakage matrix.

Figure \ref{fig:sag-diag} is a simplified diagram of the simulated circuit, consisting of a variable speed feed conveyor, \gls{SAG} mill with variable speed motor, pump box, pump, and a bank of hydro-cyclones.
\begin{figure}[ht]
	\centering
	\includegraphics[width=12.5cm]{images/sag-circuit-diag.pdf}
	\caption{Simplified process flow diagram}
	\label{fig:sag-diag}
\end{figure}

For the purposes of this work, two ore feed streams with different \gls{PSD}s were simulated. Each stream is a different mix of two different ores. One ore has a fine \gls{PSD} and the other is coarse. The mix for stream \#1 (`mix 1') consists of 22.83\% coarse ore (\textit{mix factor} of 0.2283) and mix \#2 is an even mix of both ores (mix factor of 0.5). The two streams are mixed before discharging onto the conveyor. Figure \ref{fig:coarse_fine_psd_plot} shows the \gls{PSD}s of the two mixtures.

\begin{figure}[ht]
	\centering
	\includegraphics[width=9cm]{images/coarse_fine_cumpsd_plot.pdf}
	\caption{Ore particle size distributions}
	\label{fig:coarse_fine_psd_plot}
\end{figure}

The simulated instrumentation is also illustrated in Figure \ref{fig:sag-diag}. The \gls{SAG} mill water addition set-point is set by ratio control to a fraction of the fresh ore feed rate, which is measured on the conveyor. This water addition ratio is also manipulated. The pump-box level has a PI (proportional-integral) controller to control the level to a fixed set-point by manipulating the water addition flow rate set-point. The discharge pump speed is fixed. Conveyor speed is adjusted automatically in response to the fresh ore feed rate set-point. The \gls{SAG} rotational speed set-point may also be manipulated.

The measurable process variables used in this work are the mill weight, which includes the weight of the shell and liners as well as the mill contents, mill power consumption, the solids-content of the cyclone feed stream, and the particle size (P80) of the ground product in the cyclone overflow. Mill filling level and other simulation variables are available for analysis but are assumed to be unmeasured in the real operation and therefore not available for process control.  Figure \ref{fig:grind_sim_io_diag} summarizes the inputs and outputs of the simulation model. Table \ref{tb:grind-vars} lists the normal operating points, units, and minimum and maximum operating limits of each variable.

\begin{figure}[ht]
	\centering
	\includegraphics[width=15cm]{images/grind_sim_io_diag.pdf}
	\caption{Grinding simulation model inputs and outputs}
	\label{fig:grind_sim_io_diag}
\end{figure}

%TODO: Table of process variables and normal operating points, limits etc.
\begin{table}[ht]
	\centering
	\caption{Grinding simulation model inputs and outputs} \label{tb:grind-vars}
	% See: https://texblog.org/2019/06/03/control-the-width-of-table-columns-tabular-in-latex/
	% Also: https://www.overleaf.com/learn/latex/Tables
	\begin{tabular}{c c >{\raggedright}p{5.5cm} c c c c}
		%\toprule
		& Label & Description & Op. pt. & Units & Min. & Max \\
		\midrule
		\multicolumn{7}{l}{\textit{manipulated variables}} \\
		%\midrule
		  & MV1       & Ore feed rate & 122.7 & tons/h & 0 & 200 \\   
		  & MV2       & Mill speed (fraction of critical speed) & 0.77 & - & 0 & 0.85 \\ 
		  & MV3       & Water addition ratio (fraction of ore feed rate) & 0.341 & - & 0 & 1 \\ 
		%\midrule
		\multicolumn{7}{l}{\textit{Unmeasured disturbance input}} \\
		%\midrule
		  & UD1        & Ore mix factor & 0.2283 & - & 0 & 1  \\ 
		%\midrule
		\multicolumn{7}{l}{\textit{Output variables}} \\
		%\midrule
		  & OV1        & Mill weight & 279.4 & tons & 100 & 320  \\ 
		  & OV2       & Mill power consumption & 2391 & kW & 0 & 2400  \\ 
		  & OV3       & Cyclone feed solids fraction & 61.4 & \% & 50 & 70  \\ 
		  & OV4       & Cyclone overflow P80 & 105.4 & \% & 0 & 200  \\ 
		\bottomrule
	\end{tabular}
\end{table}

To better understand the relationships between the input and output variables, a set of simulations were carried out to determine steady-state operating conditions in the vicinity of the normal operating point. Figure \ref{fig:grind_sim_ss_plot1} shows how the steady-state values of the four output variables are affected by changes in the mill fill level (fraction of internal volume occupied by the charge) and rotation speed. The normal operating points are also shown, represented by solid markers. For these simulations, a simple PI controller was used to control the mill filling level by manipulating the ore feed rate and each simulation was run until all variables converged to steady-state values. However, no constraints were imposed during these simulations, therefore power consumption exceeds the maximum possible in some cases.

These results are equivalent to the grind curves proposed by \cite{powell_applying_2009} for evaluating steady-state characteristics and optimal operating points for \gls{SAG} mills. However, compared to the curves presented by \cite{powell_applying_2009}, which were based on measurements from real operations, these are noticeably much closer to straight lines (i.e. linear relationships).

A similar set of simulations were carried out to understand the effect of changing the ore mix factor on the steady-state values of the output variables. The results are shown in Figure \ref{fig:grind_sim_ss_plot2}. From these it can be seen that the change in ore mix has no effect on the steady-state power consumption of the mill. However, there are changes in the steady-state throughput (ore feed rate), cyclone feed solids fraction, and product particle size. The throughput is approximately 4 tons-per-hour higher and the product particle size is 1.5 microns smaller when the ore mix contains the higher fraction (0.5) of coarse ore.

\begin{figure}[ht]
	\centering
	\includegraphics[width=15cm]{images/grind_sim_ss_plot1.pdf}
	\caption{Steady-state operating points}
	\label{fig:grind_sim_ss_plot1}
\end{figure}

\begin{figure}[ht]
	\centering
	\includegraphics[width=15cm]{images/grind_sim_ss_plot2.pdf}
	\caption{Effect of ore mix factor on steady-state operating points}
	\label{fig:grind_sim_ss_plot2}
\end{figure}

Zero-mean Gaussian measurement noises are added to the outputs of the simulation model to simulate measurement errors. The standard deviations of these noises are shown in Table \ref{tb:meas-noise}. Except for the measurement noises and the input disturbance described above, the model itself is deterministic.

% Scaling factors
% 2
%& 0.0085
%& 0.01
%& 0.01
%& 2.2
%& 24
%& 0.2
%& 2

\begin{table}[h!]
	\centering
	\caption{Simulated output measurements} \label{tb:meas-noise}
	\begin{tabular}{c >{\raggedright}p{5.5cm} c c}
		Label & Description & Sampling period (hours) & Noise std. dev. \\
		\midrule
		CV1        & Mill weight & 0.05 & XX \\ 
		CV2       & Mill power consumption & 0.05 & XX \\ 
		CV3       & Cyclone feed solids fraction & 0.05 & XX \\ 
		CV4       & Cyclone overflow P80 & 0.05 & XX \\ 
		\bottomrule
	\end{tabular}
\end{table}


Although some of these process variables would likely be sampled at higher rates in practice, it is assumed, for simplicity, that they are all sampled at the same rate of 1 sample every 3 minutes (i.e. a sampling period of 0.05 hours). This was deemed to be a typical sampling rate of a standard online particle size analyser that might be used for the P80 measurement.


\section{Performance evaluation} \label{sec:evaluation}

Various metrics are used in this work to evaluate the performance of the observers. Since a simulation model of the plant is used and the input disturbances are also simulated, the true values of the system inputs and outputs (i.e. without measurement errors) are available.

The first metric is the \textit{root-mean-squared-error} (\glsadd{RMSE}\gls{RMSE}) of the system output estimates, which is an indication of the magnitude of the differences between the estimates of an output signal, $\hat{Y}_i(N)=\left\{\hat{y}_i(1),\hat{y}_i(2), ..., \hat{y}_i(N)\right\}$, and its true values, $Y_i(N)=\left\{y_i(1),y_i(2), ..., y_i(N)\right\}$, (i.e. the output estimation errors),
\begin{equation} \label{eq:rmse-calc-yest}
	\newcommand{\RMSE}{\textrm{RMSE}}
	\RMSE(\hat{Y}_i(N),Y_i(N)) = \sqrt{\frac{1}{N}\sum_{k=1}^{N}{(\hat{y}_i(k)-y_i(k))^2}}.
\end{equation}

Similarly, the \gls{RMSE} of the estimates of an unmeasured input disturbance signal, $\hat{p}_i(k)$, is
\begin{equation} \label{eq:rmse-calc-pest}
	\newcommand{\RMSE}{\textrm{RMSE}}
	\RMSE(\hat{P}_i(N),P_i(N)) = \sqrt{\frac{1}{N}\sum_{k=1}^{N}{(\hat{p}_i(k)-p_i(k))^2}}.
\end{equation}
 
As well as the overall \gls{RMSE}, two additional \gls{RMSE} metrics are used to evaluate observer performance on systems with \gls{RODD}s. The \gls{RMSE} \textit{in transition}, which is the \gls{RMSE} during a period after a random shock, is used to evaluate the response of an observer to infrequent, abrupt disturbances. The transition period is defined as the samples occurring within \gls{tset95} hours of the disturbance arriving at the input to the process, where \gls{tset95} is the \textit{settling time}, defined as the time taken for the process outputs to converge to within $\pm5\%$ of the final steady-state values. The \gls{RMSE} \textit{in steady-state} is defined as the samples occurring more than \gls{tset95} hours after a disturbance and before the next one occurs.

The fourth metric is the \textit{root-mean-squared-differences} (\glsadd{RMSD}\gls{RMSD}) in the estimates,
\begin{equation} \label{eq:rmsd-calc-yest}
	\newcommand{\RMSD}{\textrm{RMSD}}
	\RMSD(\hat{Y}_i(N)) = \sqrt{\frac{1}{N}\sum_{k=1}^{N}{(\hat{y}_i(k)-\hat{y}_i(k-1))^2}}.
\end{equation}

This is a measure of the magnitude of high frequency changes in the estimates, which is an indication of the sensitivity of an observer to measurement noise.

To simplify notation in the rest of this report, the argument $N$, indicating the length of the time series, is not always shown. Thus, $\textrm{RMSE}(\hat{Y}_i(N),Y_i(N))$ may be denoted $\textrm{RMSE}(\hat{Y}_i,Y_i)$. The capitalization of $Y$ indicates that it is a time series. Also, for \gls{SISO} systems, the subscript $i$ is redundant and dropped. Thus, $\textrm{RMSE}(\hat{Y},Y)$ is the \gls{RMSE} of the output of a system with only one output variable. However, $\textrm{RMSE}(\hat{\mathbf{Y}},\mathbf{Y})$ is used for a system with more than one output. The assumption is that this is the \gls{RMSE} averaged over all output signals, $Y_i(N)$ for $i=1, ..., n_y$.
% Removed since not doing control simulations.
%To evaluate the potential benefits of the observers in process control applications, simulations were carried out with an observer, a simulated controller, and the simulated process in closed-loop. In these cases, the \gls{RMSE}s of the control variables, $y_i(k)$, compared to a set of reference values, $R_i(N)$, is calculated to evaluate the performance of the control system,
%\begin{equation} \label{eq:rmse-calc-y}
%	\newcommand{\RMSE}{\textrm{RMSE}}
%	\RMSE(Y_i(N),R_i(N)) = \sqrt{\frac{1}{N}\sum_{k=1}^{N}{(y_i(k)-r_i(k))^2}}.
%\end{equation}
%
%In addition, the RMSD of the control actions, $u_i(k)$, is calculated to provide an indication of the sensitivity of the control system to measurement noise,
%\begin{equation} \label{eq:rmsd-calc-u}
%	\newcommand{\RMSD}{\textrm{RMSD}}
%	\RMSD(U_i(N)) = \sqrt{\frac{1}{N}\sum_{k=1}^{N}{(u_i(k)-u_i(k-1))^2}}.
%\end{equation}

Because the processes simulated in this work are stochastic, it is important to evaluate state estimators over sufficiently long simulation time periods to ensure that the results are close to the true average performance and are independent of the specific pseudo-random inputs generated for each simulation. This is particularly important when evaluating systems with \gls{RODD}s because the shocks occur infrequently. As an added precaution, identical random inputs are used when comparing the performance of two or more observers on the same system.

% Variance calc - not used
%\begin{equation} \label{eq:var-calc}
%\begin{aligned}
%	\newcommand{\Var}{\textrm{Var}} 
%	\Var(\hat{y}(k)) = \frac{1}{N}\sum_{k=1}^{N}{(\hat{y}(k)-\mu_y)^2} \\
%	\mu_y = \frac{1}{N}\sum_{k=1}^{N}{\hat{y}(k)}
%\end{aligned}
%\end{equation}
