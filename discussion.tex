% !TEX encoding = UTF-8 Unicode
\chapter*{Discussion}           % ne pas numéroter
\label{chap-discussion}         % étiquette pour renvois
\phantomsection\addcontentsline{toc}{chapter}{\nameref{chap-discussion}} % inclure dans TdM

In this section, the results presented in Chapter \ref{chap-simulation} are discussed further to identify common findings and general conclusions.

\subsection{Observer parameter selection}

Comparing the best observer parameter values selected for each of the three simulation experiments presented in Chapter \ref{chap-simulation}, it is possible to see correlations between certain observer parameters and characteristics of the simulated systems. It is interesting to see if these correlations align with intuitive interpretations based on the differences between the algorithms. Table \ref{tb:summary-all-sims} lists selected details of the three simulation experiments, including the type of process model (linear or nonlinear), the input-output dimensions of the process, the probability of the simulated shocks, \gls{epsilon}, an indication of the \textit{signal-to-noise ratio} (SNR) of the output measurements, the settling time of the process in number of sample periods, denoted \gls{Nset95}, and the selected parameter values of the multiple-model observers.
\begin{table}[ht]
	\begin{center}
		\caption{Summary of experiments -- observer parameters} \label{tb:summary-all-sims}
		% See: https://texblog.org/2019/06/03/control-the-width-of-table-columns-tabular-in-latex/
		\begin{tabular}{
				>{\centering\arraybackslash}p{0.18in}
				>{\centering\arraybackslash}p{0.52in}
				>{\centering\arraybackslash}p{0.43in}
				>{\centering\arraybackslash}p{0.24in}
				>{\centering\arraybackslash}p{0.24in}
				>{\centering\arraybackslash}p{0.26in}
				>{\centering\arraybackslash}p{1in}
				>{\centering\arraybackslash}p{1in}
				>{\centering\arraybackslash}p{0.8in}}
			Sec. & System & Dim. & \gls{epsilon} & \gls{SNR} & \gls{Nset95} & MKF--SF95 \gls{nh},\gls{nf},\gls{m},\gls{d} & MKF--SF1 \gls{nh},\gls{nf},\gls{m},\gls{d} & MKF-SP \gls{nh},\gls{nmin} \\
			\hline
			\ref{sim-obs-lin-1} & linear & \gls{SISO} & 0.01 & 10 & 9 & 8,5,1,1 & 6,6,1,2 & 10,7 \\
			\ref{sim-obs-lin-2} & linear & $2 \times 2$ & 0.01 & 5 & 26 & 116,15,2,3 & 58,18,2,5 & 46,21 \\
			\ref{sec:sim-ore-SISO} & nonlinear & \gls{SISO} & 0.01 & 1.9 & 24 & 34,60,2,10 & 26,60,2,12 & 25,23  \\
			\hline
		\end{tabular}
	\end{center}
\end{table}
The settling time of the process in sampling intervals is defined as the settling time of the output $y(k)$ to within $\pm5\%$ of the steady-state value, \gls{tset95}, divided by the sampling interval,
\begin{equation} \label{eq:Nsettle}
	\glsadd{Nset95}N_{\pm 5\%}=\frac{t_{\pm 5\%}}{T_s}.
\end{equation}
By comparing the number of hypotheses required by each of the observers, \gls{nh}, it is clear that the $2 \times 2$ (\gls{MIMO}) linear model simulations in Section \ref{sim-obs-lin-2} required a significantly higher number than the \gls{SISO} system simulations. This makes sense since the possible shock combinations is an order of magnitude higher with two independent \gls{RODD}s than it is with one.

Nevertheless, there is a difference in the number of hypotheses required between the linear \gls{SISO} system in Section \ref{sim-obs-lin-1} and the \gls{SISO} nonlinear grinding model simulations in Section \ref{sec:sim-ore-SISO}. There are various possible explanations for the difference here. It could be the fact that the true system in the latter case is non-linear and there was a mismatch between the prediction model used by the observer and the true system dynamics. However, there is another significant difference between the two systems. The signal-to-noise ratio (\gls{SNR}) was over 5 times less in the grinding simulations. Also, the settling time of the grinding process model was 24 sample intervals compared to only 9 for the linear \gls{SISO} model. Both these attributes increase the \textit{estimation horizon}---the number of samples needed to achieve good estimates (i.e. a low error covariance). When the estimation horizon is long, hypotheses must be maintained longer before being evaluated and merged or pruned. In the case of the sequence fusion observers (MKF--SF95 and MKF--SF1), this is achieved by increasing the detection interval length. From the values of \gls{d} in the table, it can be seen that this is indeed the case. In the case of the sequence pruning observer (MKF--SP1), a long estimation horizon is achieved by a longer minimum life of the hypotheses, \gls{nmin}. The results show that this is also the case.

Something worth noting about the sequence pruning algorithm is the relationship between the best values of the two parameters, \gls{nh} and \gls{nmin}. Note that in the case of the $2 \times 2$ system, two new hypotheses are generated every sample time, whereas in the case of the \gls{SISO} system only one is. This means that at any point in time, $\gls{np}\gls{nmin}$ hypotheses have not reached minimum life, where \gls{np} is the number of independent shock variables. Therefore, the number of hypotheses which have reached or exceeded the minimum life is $\gls{nh}-\gls{np}\gls{nmin}$. This number is 2 or 3 in the case of the \gls{SISO} systems and 4 in the case of the $2 \times 2$ system, indicating that for some reason, there is no benefit in maintaining more than a small number of hypotheses beyond the minimum life. Thus, the minimum life parameter, \gls{nmin}, is effectively the sole decision variable, and a good value for \gls{nh} may be found using a simple heuristic such as
\begin{equation} \label{eq:nh-sp}
	\gls{nh} = \gls{np}(\gls{nmin}+2).
\end{equation}

One thing that is contrary to expectations is the number of hypotheses needed by the sequence fusion algorithms compared to the sequence pruning algorithm. \cite{robertson_method_1998} stated that the sequence pruning algorithm with detection intervals is designed to reduce the number of hypotheses required when the detection horizon is long, especially when there is more than one \gls{RODD} to distinguish between. In both the $2 \times 2$ simulation and the grinding process simulations, MKF--SP1 requires less hypotheses than either MKF--SF95 or MKF--SF1. Nevertheless, the number of hypotheses used by the 1998 version of the algorithm is significantly less than that of the 1995 version in this simulation, so it is an improvement in this respect.

The shock probability, \gls{epsilon}, was the same in all experiments, so its effect on the observer parameters cannot be determined from these results.

\subsection{Multiple-model observer advantages and disadvantages}

% Text from IFAC paper
While the multi-model observer has a number of clear advantages over a single Kalman filter, its limitations are important to recognize. Firstly, the higher variance of the noise model during the transitions, which is needed for a fast response, also increases the variance of the estimates during these periods, resulting in larger errors---46\% higher than those of KF3 during transition periods.

Secondly, the multiple-model algorithm is limited to infrequently-occurring disturbances where the disturbance model is known. Finally, the complexity of the algorithm is a significant disadvantage from the perspective of practical implementation.



